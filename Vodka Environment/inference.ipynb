{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0313464f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# ✅ WHAT YOU MUST UPDATE IF TRAINING SCRIPT CHANGES\n",
    "\n",
    "Any time you change preprocessing or architecture in the **training script**, you must copy over the same edits into this inference script in these sections:\n",
    "\n",
    "### ✅ 1️⃣ 7-mer encoding\n",
    "\n",
    "```python\n",
    "def encode_7mer(...)\n",
    "```\n",
    "\n",
    "### ✅ 2️⃣ Numeric feature selection\n",
    "\n",
    "```python\n",
    "numeric_feats = g[[ ... ]]\n",
    "```\n",
    "\n",
    "### ✅ 3️⃣ Model architecture\n",
    "\n",
    "```python\n",
    "class AttentionMIL(...)\n",
    "```\n",
    "\n",
    "and `input_dim`, `hidden_dim` if changed.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d68c4278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 0. Imports & Setup\n",
    "# =========================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d8e96fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Raw File/dataset2.csv\n",
      "Encoding 7mers\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 1. Load dataset.csv\n",
    "# =========================\n",
    "file_path = \"Raw File/\"\n",
    "file_name = \"dataset2.csv\"\n",
    "\n",
    "print(f\"Loading {file_path}{file_name}\")\n",
    "reads_df = pd.read_csv(f\"{file_path}{file_name}\")\n",
    "\n",
    "columns_to_drop = ['Unnamed: 0']\n",
    "reads_df = reads_df.drop(columns_to_drop, axis=1, errors='ignore')\n",
    "\n",
    "# sorry cherron i cannot with the colnames\n",
    "reads_df = reads_df.rename(columns={\n",
    "    'ID': 'transcript_id',\n",
    "    'POS': 'transcript_position',\n",
    "    'SEQ': '7mer'\n",
    "})\n",
    "reads_df['n_reads'] = reads_df.groupby(['transcript_id', 'transcript_position']).transform('size')\n",
    "# =========================\n",
    "# 2. 7-mer Encoding (MUST MATCH TRAINING)\n",
    "# =========================\n",
    "print(\"Encoding 7mers\")\n",
    "def encode_drach_compact(seq):\n",
    "    \"\"\"\n",
    "    Compact one-hot encoding of a 7-mer centered on a DRACH motif.\n",
    "    Positions:\n",
    "    - 0: full one-hot (A,C,G,T) → 4 dims\n",
    "    - 1: D (A,G,T) → 3 dims\n",
    "    - 2: R (A,G)   → 2 dims\n",
    "    - 3: A (fixed) → 0 dims\n",
    "    - 4: C (fixed) → 0 dims\n",
    "    - 5: H (A,C,T) → 3 dims\n",
    "    - 6: full one-hot (A,C,G,T) → 4 dims\n",
    "    Total: 16-dimensional vector\n",
    "    \"\"\"\n",
    "    encoding = []\n",
    "\n",
    "    base = seq[0]\n",
    "    encoding.extend(one_hot_base(base, ['A', 'C', 'G', 'T']))\n",
    "\n",
    "    base = seq[1]\n",
    "    encoding.extend(one_hot_base(base, ['A', 'G', 'T']))  # D\n",
    "\n",
    "    base = seq[2]\n",
    "    encoding.extend(one_hot_base(base, ['A', 'G']))       # R\n",
    "\n",
    "    # skip position 3 (always A)\n",
    "    # skip position 4 (always C)\n",
    "\n",
    "    base = seq[5]\n",
    "    encoding.extend(one_hot_base(base, ['A', 'C', 'T']))  # H\n",
    "\n",
    "    base = seq[6]\n",
    "    encoding.extend(one_hot_base(base, ['A', 'C', 'G', 'T']))\n",
    "\n",
    "    return np.array(encoding, dtype=np.float32)\n",
    "\n",
    "def one_hot_base(base, allowed):\n",
    "    \"\"\"One-hot encode base using only allowed bases.\"\"\"\n",
    "    vec = [0] * len(allowed)\n",
    "    if base in allowed:\n",
    "        vec[allowed.index(base)] = 1\n",
    "    return vec\n",
    "\n",
    "reads_df['7mer_emb'] = reads_df['7mer'].apply(encode_drach_compact)\n",
    "\n",
    "# =========================\n",
    "# 3. Dataset Class (NO LABELS NEEDED)\n",
    "# =========================\n",
    "class MILReadDatasetInference(Dataset):\n",
    "    def __init__(self, reads_df, n_reads_per_site=None):\n",
    "        \"\"\"\n",
    "        reads_df: DataFrame of read-level features with columns like\n",
    "                  ['transcript_id', 'transcript_position', '7mer_emb', 'dwell_-1', ...]\n",
    "        n_reads_per_site: int or None\n",
    "            - int: maximum number of reads per site (randomly sampled)\n",
    "            - None: use all reads\n",
    "        \"\"\"\n",
    "        self.n_reads_per_site = n_reads_per_site\n",
    "        # group by site (transcript_id, transcript_position)\n",
    "        self.groups = reads_df.groupby(['transcript_id','transcript_position'])\n",
    "        self.bags = list(self.groups.groups.keys())\n",
    "        self.reads_df = reads_df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.bags)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tid, pos = self.bags[idx]\n",
    "        g = self.groups.get_group((tid,pos))\n",
    "\n",
    "        # numeric features\n",
    "        numeric_feats = g[['PreTime','PreSD','PreMean',\n",
    "                           'InTime','InSD','InMean',\n",
    "                           'PostTime','PostSD','PostMean']].values.astype(np.float32)\n",
    "\n",
    "        # k-mer embedding\n",
    "        kmer_emb = np.stack(g['7mer_emb'].values)\n",
    "        \n",
    "        # concatenate numeric + embedding\n",
    "        bag = np.concatenate([numeric_feats, kmer_emb], axis=1)\n",
    "\n",
    "        # ------------------------\n",
    "        # Handle n_reads_per_site\n",
    "        # ------------------------\n",
    "        if self.n_reads_per_site is not None and bag.shape[0] > self.n_reads_per_site:\n",
    "            # randomly sample n_reads_per_site reads\n",
    "            indices = np.random.choice(bag.shape[0], self.n_reads_per_site, replace=False)\n",
    "            bag = bag[indices]\n",
    "        \n",
    "        return torch.tensor(bag), tid, pos\n",
    "\n",
    "# Create dataset & dataloader\n",
    "inference_ds = MILReadDatasetInference(reads_df)\n",
    "inference_loader = torch.utils.data.DataLoader(inference_ds, batch_size=1, shuffle=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a769e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded trained model weights\n",
      "Saved predictions of dataset2.csv to Results/results_of_dataset2.csv\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 4. Define Model (MUST MATCH TRAINING)\n",
    "# =========================\n",
    "class AttentionMIL(nn.Module):\n",
    "    def __init__(self, input_dim=25, hidden_dim=64):\n",
    "        super().__init__()\n",
    "        self.instance_encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "        self.classifier = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, bag):\n",
    "        H = self.instance_encoder(bag)  \n",
    "        A = torch.softmax(self.attention(H), dim=0)  \n",
    "        M = torch.sum(A * H, dim=0)  \n",
    "        out = torch.sigmoid(self.classifier(M))\n",
    "        return out, A\n",
    "\n",
    "model = AttentionMIL(input_dim=25, hidden_dim=64).to(device)\n",
    "model.load_state_dict(torch.load(\"models/epoch38_valpr0.42.pth\", map_location=device))\n",
    "model.eval()\n",
    "print(\"Loaded trained model weights\")\n",
    "\n",
    "# =========================\n",
    "# 5. Inference & Output\n",
    "# =========================\n",
    "output_rows = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for bag, tid, pos in inference_loader:\n",
    "        bag = bag[0].to(device)\n",
    "        out, _ = model(bag)\n",
    "        output_rows.append({\n",
    "            'transcript_id': tid[0],\n",
    "            'transcript_position': pos.item(),\n",
    "            'score': out.item()\n",
    "        })\n",
    "\n",
    "output_file_name = f\"results_of_{file_name}\"\n",
    "output_file_path = \"Results/\"\n",
    "output_df = pd.DataFrame(output_rows)\n",
    "output_df.to_csv(f\"{output_file_path}{output_file_name}\", index=False)\n",
    "\n",
    "print(f\"Saved predictions of {file_name} to {output_file_path}{output_file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643c064b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1283e0ef-f18e-4ff1-862e-1da3674c8485",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4161977c-4803-4ca8-82dd-de9fff63f943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import normaltest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from custom import HMM, KNN\n",
    "from statsmodels.stats.multitest import multipletests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069a85b7-78ed-4658-b110-7edb1d2dc860",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93e1d1a2-18c4-437a-ade7-cfac59643bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>POS</th>\n",
       "      <th>SEQ</th>\n",
       "      <th>PreTime</th>\n",
       "      <th>PreSD</th>\n",
       "      <th>PreMean</th>\n",
       "      <th>InTime</th>\n",
       "      <th>InSD</th>\n",
       "      <th>InMean</th>\n",
       "      <th>PostTime</th>\n",
       "      <th>PostSD</th>\n",
       "      <th>PostMean</th>\n",
       "      <th>gene_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>AAGACCA</td>\n",
       "      <td>0.00299</td>\n",
       "      <td>2.06</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.01770</td>\n",
       "      <td>10.40</td>\n",
       "      <td>122.0</td>\n",
       "      <td>0.00930</td>\n",
       "      <td>10.90</td>\n",
       "      <td>84.1</td>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>AAGACCA</td>\n",
       "      <td>0.00631</td>\n",
       "      <td>2.53</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.00844</td>\n",
       "      <td>4.67</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.01030</td>\n",
       "      <td>6.30</td>\n",
       "      <td>80.9</td>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>AAGACCA</td>\n",
       "      <td>0.00465</td>\n",
       "      <td>3.92</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.01360</td>\n",
       "      <td>12.00</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0.00498</td>\n",
       "      <td>2.13</td>\n",
       "      <td>79.6</td>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>AAGACCA</td>\n",
       "      <td>0.00398</td>\n",
       "      <td>2.06</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.00830</td>\n",
       "      <td>5.01</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.00498</td>\n",
       "      <td>3.78</td>\n",
       "      <td>80.4</td>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>AAGACCA</td>\n",
       "      <td>0.00664</td>\n",
       "      <td>2.92</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.00266</td>\n",
       "      <td>3.94</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.01300</td>\n",
       "      <td>7.15</td>\n",
       "      <td>82.2</td>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID  POS      SEQ  PreTime  PreSD  PreMean   InTime   InSD  \\\n",
       "0  ENST00000000233  244  AAGACCA  0.00299   2.06    125.0  0.01770  10.40   \n",
       "1  ENST00000000233  244  AAGACCA  0.00631   2.53    125.0  0.00844   4.67   \n",
       "2  ENST00000000233  244  AAGACCA  0.00465   3.92    109.0  0.01360  12.00   \n",
       "3  ENST00000000233  244  AAGACCA  0.00398   2.06    125.0  0.00830   5.01   \n",
       "4  ENST00000000233  244  AAGACCA  0.00664   2.92    120.0  0.00266   3.94   \n",
       "\n",
       "   InMean  PostTime  PostSD  PostMean          gene_id  label  \n",
       "0   122.0   0.00930   10.90      84.1  ENSG00000004059      0  \n",
       "1   126.0   0.01030    6.30      80.9  ENSG00000004059      0  \n",
       "2   124.0   0.00498    2.13      79.6  ENSG00000004059      0  \n",
       "3   130.0   0.00498    3.78      80.4  ENSG00000004059      0  \n",
       "4   129.0   0.01300    7.15      82.2  ENSG00000004059      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"output_w_label.csv\").drop('Unnamed: 0', axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fde643-35d9-46b5-9f88-293a14cf78c6",
   "metadata": {},
   "source": [
    "## Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83869948-9b89-441f-831e-ff46dda3457a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['PreTime', 'InTime', 'PostTime']  # columns to transform\n",
    "df.loc[:, cols] = np.cbrt(df[cols])  # inplace modification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e822ecce-402a-41b9-98d4-55ee464cb7e5",
   "metadata": {},
   "source": [
    "## Segmentation\n",
    "\n",
    "Yes, the split is not really accurate - but it's close enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77b9445d-c903-4869-a3e2-b45087ff9f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(x):\n",
    "\n",
    "    unique_x =x[['gene_id', 'label']].drop_duplicates()\n",
    "    X_train, X_non_train, y_train, y_non_train = train_test_split(\n",
    "        unique_x['gene_id'], unique_x['label'], test_size=0.2, stratify=unique_x['label'], random_state=42\n",
    "    )\n",
    "\n",
    "    X_test, X_val , y_test, y_val = train_test_split(\n",
    "        X_non_train, y_non_train, test_size=0.5, stratify=y_non_train, random_state=42\n",
    "    )\n",
    "\n",
    "    return X_train, X_val, X_test\n",
    "\n",
    "gene_train, gene_val, gene_test = split(df) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d36cf58-10e7-4ef4-a641-731e1d2bc2c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>POS</th>\n",
       "      <th>SEQ</th>\n",
       "      <th>PreTime</th>\n",
       "      <th>PreSD</th>\n",
       "      <th>PreMean</th>\n",
       "      <th>InTime</th>\n",
       "      <th>InSD</th>\n",
       "      <th>InMean</th>\n",
       "      <th>PostTime</th>\n",
       "      <th>PostSD</th>\n",
       "      <th>PostMean</th>\n",
       "      <th>gene_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>AAGACCA</td>\n",
       "      <td>0.144065</td>\n",
       "      <td>2.06</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.260610</td>\n",
       "      <td>10.40</td>\n",
       "      <td>122.0</td>\n",
       "      <td>0.210294</td>\n",
       "      <td>10.90</td>\n",
       "      <td>84.1</td>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>AAGACCA</td>\n",
       "      <td>0.184789</td>\n",
       "      <td>2.53</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.203601</td>\n",
       "      <td>4.67</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.217577</td>\n",
       "      <td>6.30</td>\n",
       "      <td>80.9</td>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>AAGACCA</td>\n",
       "      <td>0.166911</td>\n",
       "      <td>3.92</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.238697</td>\n",
       "      <td>12.00</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0.170769</td>\n",
       "      <td>2.13</td>\n",
       "      <td>79.6</td>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>AAGACCA</td>\n",
       "      <td>0.158475</td>\n",
       "      <td>2.06</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.202469</td>\n",
       "      <td>5.01</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.170769</td>\n",
       "      <td>3.78</td>\n",
       "      <td>80.4</td>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>244</td>\n",
       "      <td>AAGACCA</td>\n",
       "      <td>0.187956</td>\n",
       "      <td>2.92</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.138557</td>\n",
       "      <td>3.94</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.235133</td>\n",
       "      <td>7.15</td>\n",
       "      <td>82.2</td>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID  POS      SEQ   PreTime  PreSD  PreMean    InTime   InSD  \\\n",
       "0  ENST00000000233  244  AAGACCA  0.144065   2.06    125.0  0.260610  10.40   \n",
       "1  ENST00000000233  244  AAGACCA  0.184789   2.53    125.0  0.203601   4.67   \n",
       "2  ENST00000000233  244  AAGACCA  0.166911   3.92    109.0  0.238697  12.00   \n",
       "3  ENST00000000233  244  AAGACCA  0.158475   2.06    125.0  0.202469   5.01   \n",
       "4  ENST00000000233  244  AAGACCA  0.187956   2.92    120.0  0.138557   3.94   \n",
       "\n",
       "   InMean  PostTime  PostSD  PostMean          gene_id  label  \n",
       "0   122.0  0.210294   10.90      84.1  ENSG00000004059      0  \n",
       "1   126.0  0.217577    6.30      80.9  ENSG00000004059      0  \n",
       "2   124.0  0.170769    2.13      79.6  ENSG00000004059      0  \n",
       "3   130.0  0.170769    3.78      80.4  ENSG00000004059      0  \n",
       "4   129.0  0.235133    7.15      82.2  ENSG00000004059      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = df[df['gene_id'].isin(gene_train)].copy()\n",
    "val = df[df['gene_id'].isin(gene_val)].copy()\n",
    "test = df[df['gene_id'].isin(gene_test)].copy()\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f79e63-05b5-473c-8ed2-bb4315f75bc3",
   "metadata": {},
   "source": [
    "### Check stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3353801-dc35-4929-833a-86dbaa09627f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c599f thead th {\n",
       "  background-color: #405D7A;\n",
       "  color: white;\n",
       "  font-weight: bold;\n",
       "  text-align: center;\n",
       "}\n",
       "#T_c599f tbody td {\n",
       "  text-align: center;\n",
       "}\n",
       "#T_c599f tbody tr:nth-child(even) {\n",
       "  background-color: #F5F5F5;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c599f\">\n",
       "  <caption>Train Validation Test Split</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_c599f_level0_col0\" class=\"col_heading level0 col0\" >Segment Set</th>\n",
       "      <th id=\"T_c599f_level0_col1\" class=\"col_heading level0 col1\" >Total Transcripts</th>\n",
       "      <th id=\"T_c599f_level0_col2\" class=\"col_heading level0 col2\" >Pos Transcripts</th>\n",
       "      <th id=\"T_c599f_level0_col3\" class=\"col_heading level0 col3\" >Proportion (Positive/Total)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_c599f_row0_col0\" class=\"data row0 col0\" >Train</td>\n",
       "      <td id=\"T_c599f_row0_col1\" class=\"data row0 col1\" >108,534</td>\n",
       "      <td id=\"T_c599f_row0_col2\" class=\"data row0 col2\" >5,248</td>\n",
       "      <td id=\"T_c599f_row0_col3\" class=\"data row0 col3\" >4.84%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c599f_row1_col0\" class=\"data row1 col0\" >Validation</td>\n",
       "      <td id=\"T_c599f_row1_col1\" class=\"data row1 col1\" >16,002</td>\n",
       "      <td id=\"T_c599f_row1_col2\" class=\"data row1 col2\" >1,186</td>\n",
       "      <td id=\"T_c599f_row1_col3\" class=\"data row1 col3\" >7.41%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c599f_row2_col0\" class=\"data row2 col0\" >Testing</td>\n",
       "      <td id=\"T_c599f_row2_col1\" class=\"data row2 col1\" >16,774</td>\n",
       "      <td id=\"T_c599f_row2_col2\" class=\"data row2 col2\" >1,106</td>\n",
       "      <td id=\"T_c599f_row2_col3\" class=\"data row2 col3\" >6.59%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c599f_row3_col0\" class=\"data row3 col0\" >Total</td>\n",
       "      <td id=\"T_c599f_row3_col1\" class=\"data row3 col1\" >121,838</td>\n",
       "      <td id=\"T_c599f_row3_col2\" class=\"data row3 col2\" >5,475</td>\n",
       "      <td id=\"T_c599f_row3_col3\" class=\"data row3 col3\" >4.49%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1f1dda04100>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample dataframe\n",
    "all_segments = [train, val, test, df]\n",
    "\n",
    "def get_transcripts(df):\n",
    "    return df.drop_duplicates(subset=['ID', 'POS']).shape[0]\n",
    "\n",
    "def get_positive_transcripts(df):\n",
    "    return df[df['label'] == 1].drop_duplicates(subset=['ID', 'POS']).shape[0]\n",
    "    \n",
    "\n",
    "\n",
    "tab = pd.DataFrame({\n",
    "    'Segment Set': ['Train', 'Validation', 'Testing','Total'],\n",
    "    'Total Transcripts': map(get_transcripts, all_segments),\n",
    "    'Pos Transcripts': map(get_positive_transcripts, all_segments),\n",
    "    'Proportion (Positive/Total)': map(lambda x: x[0]/x[1], list(zip(map(get_positive_transcripts, all_segments),map(get_transcripts, all_segments)))),\n",
    "    \n",
    "})\n",
    "\n",
    "# Style with nice header\n",
    "styled_tab = (tab.style\n",
    "    .set_caption('Train Validation Test Split')\n",
    "    .hide()\n",
    "    .set_table_styles([\n",
    "        {'selector': 'thead th', \n",
    "         'props': [('background-color', '#405D7A'),\n",
    "                   ('color', 'white'),\n",
    "                   ('font-weight', 'bold'),\n",
    "                   ('text-align', 'center')]},\n",
    "        {'selector': 'tbody td', \n",
    "         'props': [('text-align', 'center')]},\n",
    "        {'selector': 'tbody tr:nth-child(even)', \n",
    "         'props': [('background-color', '#F5F5F5')]}\n",
    "    ])\n",
    "    .format({\n",
    "        'Total Transcripts': '{:,.0f}',  # Thousand separators, no decimals\n",
    "        'Pos Transcripts': '{:,.0f}',  # Thousand separators, no decimals\n",
    "        'Proportion (Positive/Total)': '{:.2%}'  # Percentage format with 2 decimals\n",
    "    })\n",
    ")\n",
    "\n",
    "styled_tab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc1f6fc-2783-4d50-b5d6-da62d8d6a01c",
   "metadata": {},
   "source": [
    "### Remove some data\n",
    "\n",
    "1. Remove last character of sequence\n",
    "2. Replace T with A in the 6th character\n",
    "\n",
    "To reduce number of models to fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89b460fc-c8e3-4ba3-8f63-cdbc6274872c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_segmented = {\n",
    "    newseq: g\n",
    "    for newseq, g in train.assign(\n",
    "        newSEQ = train['SEQ'].str[:5] + train['SEQ'].str.get(5).replace({'C': 'A'})\n",
    "    ).groupby('newSEQ')\n",
    "}\n",
    "\n",
    "val_segmented = {\n",
    "    newseq: g\n",
    "    for newseq, g in test.assign(\n",
    "        newSEQ = val['SEQ'].str[:5] + val['SEQ'].str.get(5).replace({'C': 'A'})\n",
    "    ).groupby('newSEQ')\n",
    "}\n",
    "\n",
    "test_segmented = {\n",
    "    newseq: g\n",
    "    for newseq, g in test.assign(\n",
    "        newSEQ = test['SEQ'].str[:5] + test['SEQ'].str.get(5).replace({'C': 'A'})\n",
    "    ).groupby('newSEQ')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cd30671-8a17-4e1c-bc22-aac7b90bcd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# --- Example setup ---\n",
    "# df = your DataFrame with columns: ['SEQ', 'x1', 'x2', ..., 'x12']\n",
    "def get_closest_neighbours(df, SEQ, n_neighbors = 5):\n",
    "    # Separate identifier and features\n",
    "    seqs = df[SEQ]\n",
    "    X = df.drop(columns=[SEQ])\n",
    "    \n",
    "    # --- Step 1: Standardize ---\n",
    "    X_scaled = StandardScaler().fit_transform(X)\n",
    "    \n",
    "    # --- Step 2: PCA to 3 components ---\n",
    "    pca = PCA(n_components=3)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    \n",
    "    # --- Step 3: Nearest Neighbors (find 5 closest per point) ---\n",
    "    # n_neighbors=6 includes the point itself, so we'll exclude it later\n",
    "    nn = NearestNeighbors(n_neighbors=n_neighbors+1, metric='euclidean')\n",
    "    nn.fit(X_pca)\n",
    "    \n",
    "    distances, indices = nn.kneighbors(X_pca)\n",
    "    \n",
    "    # --- Step 4: Build a mapping of each SEQ to its nearest 4â€“5 neighbors ---\n",
    "    neighbors_dict = {}\n",
    "    for i, seq in enumerate(seqs):\n",
    "        neighbor_indices = indices[i][1:]  # skip the first one (itself)\n",
    "        neighbors_dict[seq] = seqs.iloc[neighbor_indices].tolist()\n",
    "    \n",
    "    return neighbors_dict\n",
    "\n",
    "def summarize_group(group):\n",
    "    numeric_cols = group.select_dtypes(include=[np.number]).columns\n",
    "    numeric_cols = numeric_cols.difference(['POS', 'label'])\n",
    "    \n",
    "    summary = {}\n",
    "    for col in numeric_cols:\n",
    "        values = group[col].dropna()\n",
    "        mean = values.mean()\n",
    "        sd = values.std(ddof=1)\n",
    "\n",
    "        summary[f\"{col}_mean\"] = mean\n",
    "        summary[f\"{col}_sd\"] = sd\n",
    "\n",
    "    return pd.Series(summary)\n",
    "\n",
    "summaries = []\n",
    "for newseq, g in train_segmented.items():\n",
    "    s = summarize_group(g)\n",
    "    s.name = newseq\n",
    "    summaries.append(s)\n",
    "\n",
    "# --- Step 4: Combine into final summary DataFrame ---\n",
    "summary_df = pd.DataFrame(summaries).reset_index().rename(columns={'index': 'newSEQ'})\n",
    "\n",
    "closest_neighbours = get_closest_neighbours(summary_df, 'newSEQ', n_neighbors = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b3445cae-3861-4017-b410-a5ab6a5ef7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_HMM_input(df):\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    x_var = scaler.fit_transform(df[['PreTime', 'PreSD', 'PreMean', \n",
    "               'InTime', 'InSD', 'InMean', \n",
    "               'PostTime', 'PostSD', 'PostMean']])\n",
    "    \n",
    "    x_var = x_var.reshape(-1,3,3)\n",
    "    '''\n",
    "    y_var = np.column_stack([\n",
    "        np.zeros(len(df), dtype=int),\n",
    "        df['label'].to_numpy() + 1,\n",
    "        np.full(len(df), 3, dtype=int)\n",
    "    ])'''\n",
    "    y_var = df[['label']]\n",
    "\n",
    "    return x_var, y_var\n",
    "\n",
    "def dataframe_to_HMM_input_scaled(df, scale):\n",
    "\n",
    "    x_var = scaler.transform(df[['PreTime', 'PreSD', 'PreMean', \n",
    "               'InTime', 'InSD', 'InMean', \n",
    "               'PostTime', 'PostSD', 'PostMean']])\n",
    "    \n",
    "    x_var = x_var.reshape(-1,3,3)\n",
    "    '''\n",
    "    y_var = np.column_stack([\n",
    "        np.zeros(len(df), dtype=int),\n",
    "        df['label'].to_numpy() + 1,\n",
    "        np.full(len(df), 3, dtype=int)\n",
    "    ])'''\n",
    "    y_var = df[['label']]\n",
    "\n",
    "    return x_var, y_var\n",
    "\n",
    "def dataframe_to_KNN_input(df):\n",
    "    x_var = df[['PreTime', 'PreSD', 'PreMean', \n",
    "               'InTime', 'InSD', 'InMean', \n",
    "               'PostTime', 'PostSD', 'PostMean']]\n",
    "\n",
    "    y_var = df[['label']]\n",
    "\n",
    "    return x_var, y_var\n",
    "\n",
    "def attach_positive(old_df, new_df):\n",
    "\n",
    "    return pd.concat([old_df, new_df[new_df['label']==1]])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3561b6d8-9751-4c39-9ece-7bb2dcf7fe1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(466451, 15)\n",
      "(248595, 15)\n",
      "(8280, 15)\n",
      "(474731, 15)\n"
     ]
    }
   ],
   "source": [
    "# Check attach_positive valid\n",
    "\n",
    "print(train_segmented[list(train_segmented.keys())[0]].shape)\n",
    "print(train_segmented[list(train_segmented.keys())[1]].shape)\n",
    "print((lambda x: x[x['label']==1].shape) (train_segmented[list(train_segmented.keys())[1]]) )\n",
    "print(attach_positive(train_segmented[list(train_segmented.keys())[0]],\n",
    "                     train_segmented[list(train_segmented.keys())[1]]).shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcc8035-5a8c-4617-9f86-90816f0497aa",
   "metadata": {},
   "source": [
    "### Actual fitting\n",
    "\n",
    "Time to run: 30 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "c577acf9-98bc-4afe-96e5-b161c872d1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 out of 48\n",
      "Best matching state: 2, flipped: False\n",
      "2 out of 48\n",
      "Best matching state: 2, flipped: True\n",
      "3 out of 48\n",
      "Best matching state: 2, flipped: False\n",
      "4 out of 48\n",
      "Best matching state: 2, flipped: True\n",
      "5 out of 48\n",
      "Best matching state: 2, flipped: False\n",
      "6 out of 48\n",
      "Best matching state: 2, flipped: True\n",
      "7 out of 48\n",
      "Best matching state: 2, flipped: False\n",
      "8 out of 48\n",
      "Best matching state: 2, flipped: True\n",
      "9 out of 48\n",
      "Best matching state: 2, flipped: False\n",
      "10 out of 48\n",
      "Best matching state: 2, flipped: False\n",
      "11 out of 48\n",
      "Best matching state: 2, flipped: False\n",
      "12 out of 48\n",
      "Best matching state: 2, flipped: False\n",
      "13 out of 48\n",
      "Best matching state: 2, flipped: True\n",
      "14 out of 48\n",
      "Best matching state: 2, flipped: False\n",
      "15 out of 48\n",
      "Best matching state: 2, flipped: True\n",
      "16 out of 48\n",
      "Best matching state: 2, flipped: True\n",
      "17 out of 48\n",
      "Best matching state: 2, flipped: False\n",
      "18 out of 48\n",
      "Best matching state: 2, flipped: True\n",
      "19 out of 48\n",
      "Best matching state: 2, flipped: True\n",
      "20 out of 48\n",
      "Best matching state: 2, flipped: True\n",
      "21 out of 48\n",
      "Best matching state: 2, flipped: True\n",
      "22 out of 48\n",
      "Best matching state: 2, flipped: True\n",
      "23 out of 48\n",
      "Best matching state: 2, flipped: True\n",
      "24 out of 48\n",
      "Best matching state: 2, flipped: False\n",
      "25 out of 48\n",
      "Best matching state: 2, flipped: False\n",
      "26 out of 48\n",
      "Best matching state: 2, flipped: False\n",
      "27 out of 48\n",
      "Best matching state: 2, flipped: False\n",
      "28 out of 48\n",
      "Best matching state: 2, flipped: True\n",
      "29 out of 48\n",
      "Best matching state: 2, flipped: True\n",
      "30 out of 48\n",
      "Best matching state: 2, flipped: True\n",
      "31 out of 48\n",
      "Best matching state: 2, flipped: False\n",
      "32 out of 48\n",
      "Best matching state: 2, flipped: False\n",
      "33 out of 48\n",
      "Best matching state: 2, flipped: True\n",
      "34 out of 48\n",
      "Best matching state: 2, flipped: True\n",
      "35 out of 48\n",
      "Best matching state: 2, flipped: False\n",
      "36 out of 48\n",
      "Best matching state: 2, flipped: False\n",
      "37 out of 48\n",
      "Best matching state: 2, flipped: True\n",
      "38 out of 48\n",
      "Best matching state: 2, flipped: True\n",
      "39 out of 48\n",
      "Best matching state: 2, flipped: True\n",
      "40 out of 48\n",
      "Best matching state: 2, flipped: False\n",
      "41 out of 48\n",
      "Best matching state: 2, flipped: False\n",
      "42 out of 48\n",
      "Best matching state: 2, flipped: False\n",
      "43 out of 48\n",
      "Best matching state: 2, flipped: True\n",
      "44 out of 48\n",
      "Best matching state: 2, flipped: False\n",
      "45 out of 48\n",
      "Best matching state: 2, flipped: False\n",
      "46 out of 48\n",
      "Best matching state: 2, flipped: False\n",
      "47 out of 48\n",
      "Best matching state: 2, flipped: False\n",
      "48 out of 48\n",
      "Best matching state: 2, flipped: False\n"
     ]
    }
   ],
   "source": [
    "y_actual = np.array([])\n",
    "y_actual_seg = []\n",
    "y_pred = np.array([])\n",
    "y_pred_seg = []\n",
    "i= 1\n",
    "\n",
    "for SEQ, df_spec in train_segmented.items():\n",
    "    print(i, \"out of\", len(train_segmented))\n",
    "\n",
    "    '''\n",
    "    if sum(df_spec['label'])/len(df_spec['label']) < 0.0001:\n",
    "        for newSEQ in closest_neighbours[SEQ]:\n",
    "            df_spec = attach_positive(df_spec, train_segmented[newSEQ])\n",
    "    \n",
    "    if sum(df_spec['label']) >0:\n",
    "        df_spec = oversample_with_noise(df_spec, label_col='label',\n",
    "                                        minority_label=1,\n",
    "                                        target=0.2,\n",
    "                                        target_type='ratio',\n",
    "                                        noise_scale=0.02,\n",
    "                                        random_state=0,\n",
    "                                        use_smote=False)  # disable SMOTE if you prefer pure noise approach\n",
    "    '''\n",
    "    X_train, y_train = dataframe_to_HMM_input(df_spec)\n",
    "    \n",
    "    X_test, y_test = dataframe_to_HMM_input(val_segmented[SEQ])\n",
    "    i = i + 1\n",
    "    try:\n",
    "        model, post_middle = HMM(X_train, X_test, y_train)\n",
    "    \n",
    "        y_pred = np.append(y_pred, post_middle)\n",
    "        y_actual = np.append(y_actual, y_test)\n",
    "    \n",
    "        y_pred_seg.append(post_middle.copy())\n",
    "        y_actual_seg.append(y_test.copy())\n",
    "        \n",
    "    except:\n",
    "        print(\"Using KNN\")\n",
    "        X_train, y_train, scale = dataframe_to_KNN_input(df_spec)\n",
    "        X_test, y_test = dataframe_to_KNN_input_scaled(val_segmented[SEQ], scale)\n",
    "        model, post_middle = KNN(X_train, y_train, X_test)\n",
    "    \n",
    "        y_pred = np.append(y_pred, post_middle)\n",
    "        y_actual = np.append(y_actual, y_test)\n",
    "    \n",
    "        y_pred_seg.append(post_middle.copy())\n",
    "        y_actual_seg.append(y_test.copy())\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "fce1a950-751b-43b0-8e14-d47170a2e1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HMM(X_train, X_test, y_train, n_repeats=1):\n",
    "\n",
    "    def build_model(p_to_node2):\n",
    "        \"\"\"Helper to construct and fit a DenseHMM with a given transition prob.\"\"\"\n",
    "        dists = [Normal() for _ in range(4)]\n",
    "        edges = np.zeros((4, 4), dtype=float)\n",
    "\n",
    "        # Transition probabilities\n",
    "        edges[0, 1] = p_to_node2\n",
    "        edges[0, 2] = 1.0 - p_to_node2\n",
    "        edges[1, 3] = 1.0\n",
    "        edges[2, 3] = 1.0\n",
    "        edges[3, :] = 0.0\n",
    "\n",
    "        starts = [1.0, 0.0, 0.0, 0.0]\n",
    "        ends   = [0.0, 0.0, 0.0, 1.0]\n",
    "\n",
    "        models = []\n",
    "        for _ in range(n_repeats):\n",
    "            model = DenseHMM(dists, edges=edges.tolist(),\n",
    "                             starts=starts, ends=ends,\n",
    "                             verbose=False, max_iter=50)\n",
    "            model._initialize(X_train)\n",
    "            model.fit(X_train)\n",
    "            models.append(model)\n",
    "        return models\n",
    "\n",
    "    def get_posteriors(models, X):\n",
    "        \"\"\"Predict posterior probabilities, filtering out any NaN results.\"\"\"\n",
    "        posterior_list = []\n",
    "        for i, m in enumerate(models):\n",
    "            try:\n",
    "                probs = m.predict_proba(X)\n",
    "                if not np.isnan(probs).any():\n",
    "                    posterior_list.append(probs)\n",
    "                else:\n",
    "                    print(f\"[Model {i}] skipped due to NaN values.\")\n",
    "            except Exception as e:\n",
    "                print(f\"[Model {i}] failed: {e}\")\n",
    "        return posterior_list\n",
    "\n",
    "    # --- First attempt ---\n",
    "    p_to_node2 = 0.3\n",
    "    models = build_model(p_to_node2)\n",
    "    posterior_list = get_posteriors(models, X_test)\n",
    "\n",
    "    # --- Retry if failed ---\n",
    "    if len(posterior_list) == 0:\n",
    "        print(\"Retrying with modified transition probability...\")\n",
    "        p_to_node2 = 0.6\n",
    "        models = build_model(p_to_node2)\n",
    "        posterior_list = get_posteriors(models, X_test)\n",
    "\n",
    "    # --- If still failed, raise custom error ---\n",
    "    if len(posterior_list) == 0:\n",
    "        raise RuntimeError(\"Both attempts failed (NaNs in predictions).\")\n",
    "\n",
    "    # --- Determine correct state assignment using training data ---\n",
    "    ref_model = models[0]\n",
    "    train_probs = ref_model.predict_proba(X_train)  # (n_train, seq_len, n_states)\n",
    "    train_middle = train_probs[:, 1, :]             # take middle timestep probabilities\n",
    "\n",
    "    # Compare each state's probability vs y_train and (1 - y_train)\n",
    "    best_state = 2\n",
    "    best_distance = float(\"inf\")\n",
    "\n",
    "    p_state = train_middle[:, 2]\n",
    "\n",
    "    d1 = np.sum((p_state.detach().numpy().flatten() - y_train.to_numpy().flatten() )**2)\n",
    "    d2 = np.sum(((1 - p_state.detach().numpy().flatten()) - y_train.to_numpy().flatten() )**2)\n",
    "\n",
    "    flipped = d2 < d1  # whether to flip probabilities\n",
    "\n",
    "    print(f\"Best matching state: {best_state}, flipped: {flipped}\")\n",
    "\n",
    "    # --- Aggregate results ---\n",
    "    posterior_array = np.stack(posterior_list, axis=0)\n",
    "    posterior_mean = np.nanmean(posterior_array, axis=0)\n",
    "    post_middle = posterior_mean[:, 1, :]\n",
    "\n",
    "    # Ensure output probabilities correspond to correct positive state\n",
    "    prob_pos = post_middle[:, best_state]\n",
    "    if flipped:\n",
    "        prob_pos = 1 - prob_pos\n",
    "\n",
    "    return models, prob_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2df9634d-a5a7-44f3-9c2a-4bbc14ede9af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3092"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred_seg[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9e3ac044-71b6-48cf-9af3-a0a7c55ea932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAAACA 0.327 0.041 0.004\n",
      "AAAACT 0.347 0.0 0.033\n",
      "AAGACA 0.271 0.0 0.014\n",
      "AAGACT 0.307 0.133 0.114\n",
      "AGAACA 0.113 0.01 0.024\n",
      "AGAACT 0.258 0.2 0.135\n",
      "AGGACA 0.257 0.172 0.074\n",
      "AGGACT 0.278 0.118 0.247\n",
      "ATAACA 0.016 0.0 0.0\n",
      "ATAACT 0.097 0.0 0.02\n",
      "ATGACA 0.159 0.0 0.007\n",
      "ATGACT 0.319 0.0 0.052\n",
      "CAAACA 0.336 0.0 0.003\n",
      "CAAACT 0.166 0.0 0.031\n",
      "CAGACA 0.272 0.036 0.011\n",
      "CAGACT 0.37 0.072 0.079\n",
      "CGAACA 0.059 0.0 0.021\n",
      "CGAACT 0.075 0.0 0.087\n",
      "CGGACA 0.372 0.348 0.056\n",
      "CGGACT 0.372 0.403 0.325\n",
      "CTAACA 0.134 0.0 0.003\n",
      "CTAACT 0.049 0.0 0.008\n",
      "CTGACA 0.307 0.103 0.019\n",
      "CTGACT 0.341 0.123 0.081\n",
      "GAAACA 0.286 0.0 0.01\n",
      "GAAACT 0.305 0.163 0.032\n",
      "GAGACA 0.156 0.0 0.016\n",
      "GAGACT 0.281 0.198 0.125\n",
      "GGAACA 0.073 0.0 0.024\n",
      "GGAACT 0.274 0.228 0.122\n",
      "GGGACA 0.229 0.04 0.083\n",
      "GGGACT 0.297 0.0 0.243\n",
      "GTAACA 0.048 0.0 0.002\n",
      "GTAACT 0.097 0.0 0.018\n",
      "GTGACA 0.242 0.047 0.031\n",
      "GTGACT 0.289 0.188 0.084\n",
      "TAAACA 0.062 0.0 0.003\n",
      "TAAACT 0.109 0.0 0.031\n",
      "TAGACA 0.169 0.0 0.023\n",
      "TAGACT 0.237 0.0 0.056\n",
      "TGAACA 0.116 0.049 0.032\n",
      "TGAACT 0.223 0.157 0.118\n",
      "TGGACA 0.384 0.042 0.084\n",
      "TGGACT 0.385 0.723 0.273\n",
      "TTAACA 0.085 0.0 0.0\n",
      "TTAACT 0.111 0.064 0.022\n",
      "TTGACA 0.291 0.0 0.007\n",
      "TTGACT 0.304 0.0 0.054\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(y_actual_seg)):\n",
    "    seq_list = list(train_segmented.keys())\n",
    "    print(seq_list[i], \n",
    "          np.round(np.mean((y_actual_seg[i].to_numpy()-y_pred_seg[i])**2),decimals=3 ),\n",
    "          np.round(np.sum(y_actual_seg[i].to_numpy())/y_actual_seg[i].shape[0],decimals=3),\n",
    "          np.round(np.sum(train_segmented[seq_list[i]]['label'].to_numpy())/train_segmented[seq_list[i]]['label'].to_numpy().shape[0],decimals=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "bcd56526-a9d0-47e3-afb0-bb7b24f0fbf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87350,)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_actual.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "bdb7752f-c1c8-4fa6-884e-6f0c90d10ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ~np.isnan(y_pred)\n",
    "filter_y_actual = y_actual[mask]\n",
    "filter_y_pred = y_pred[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e920781c-4e5c-4bff-aee7-ffcd8457e8a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'ENST00000000412'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3516\\2861595209.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[0mdf_res\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_res\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_res\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf_res\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m oversample_with_noise(\n\u001b[0m\u001b[0;32m    138\u001b[0m     \u001b[0mtest_segmented\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'AAAACT'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;34m'label'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[0mminority_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3516\\2861595209.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(df, label_col, minority_label, target, target_type, noise_scale, random_state, use_smote, smote_k_neighbors)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Try SMOTE when allowed and feasible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0muse_smote\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mminority_count\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msmote_k_neighbors\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[0msampling_strategy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mminority_label\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdesired_minority\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[0msm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msampling_strategy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msampling_strategy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msmote_k_neighbors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[0mX_res\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_res\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m         \u001b[0mdf_res\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_res\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_res\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdf_res\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[0my_resampled\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlike\u001b[0m \u001b[0mof\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn_samples_new\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mX_resampled\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m         \"\"\"\n\u001b[0;32m    207\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    102\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mX_resampled\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \"\"\"\n\u001b[0;32m    104\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[0marrays_transformer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mArraysTransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         self.sampling_strategy_ = check_sampling_strategy(\n\u001b[0;32m    109\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msampling_strategy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampling_type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, accept_sparse)\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maccept_sparse\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[0maccept_sparse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_target_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindicate_one_vs_all\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinarize_y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    646\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;34m\"estimator\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m                     \u001b[0mcheck_y_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mdefault_check_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"y\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    649\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 650\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    651\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ensure_2d\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1297\u001b[0m         raise ValueError(\n\u001b[0;32m   1298\u001b[0m             \u001b[1;34mf\"{estimator_name} requires y to be passed, but the target y is None\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1299\u001b[0m         )\n\u001b[0;32m   1300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1301\u001b[1;33m     X = check_array(\n\u001b[0m\u001b[0;32m   1302\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1303\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m         \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1009\u001b[0m                         )\n\u001b[0;32m   1010\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1011\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1012\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1013\u001b[1;33m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1014\u001b[0m                 raise ValueError(\n\u001b[0;32m   1015\u001b[0m                     \u001b[1;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m                 ) from complex_warning\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_array_api.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[0;32m    741\u001b[0m         \u001b[1;31m# Use NumPy API to support order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    743\u001b[0m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    744\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 745\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    746\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    747\u001b[0m         \u001b[1;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    748\u001b[0m         \u001b[1;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m   2167\u001b[0m             )\n\u001b[0;32m   2168\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2169\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2170\u001b[0m             \u001b[1;31m# Note: branch avoids `copy=None` for NumPy 1.x support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2171\u001b[1;33m             \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2172\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2173\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'ENST00000000412'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "\n",
    "def oversample_with_noise(\n",
    "    df,\n",
    "    label_col,\n",
    "    minority_label=1,\n",
    "    target=None,\n",
    "    target_type='ratio',   # 'ratio' or 'absolute'\n",
    "    noise_scale=0.02,      # proportion of feature std for noise\n",
    "    random_state=42,\n",
    "    use_smote=True,\n",
    "    smote_k_neighbors=5\n",
    "):\n",
    "    \"\"\"\n",
    "    Oversample df so the minority class reaches the requested target.\n",
    "\n",
    "    - df: pandas DataFrame (X and y together)\n",
    "    - label_col: name of label column in df\n",
    "    - minority_label: value representing minority class (e.g. 1)\n",
    "    - target: if target_type=='ratio', target is fraction (minority / majority)\n",
    "              if target_type=='absolute', target is absolute minority count\n",
    "              Example: target=0.5 means minority will be 50% of majority.\n",
    "    - noise_scale: fraction of per-feature std used as Gaussian noise\n",
    "    - use_smote: try SMOTE when possible, otherwise fallback to RandomOverSampler+noise\n",
    "    - smote_k_neighbors: k used by SMOTE if invoked\n",
    "    Returns: resampled DataFrame (index reset)\n",
    "    \"\"\"\n",
    "    if target is None:\n",
    "        raise ValueError(\"Provide target (ratio or absolute count).\")\n",
    "\n",
    "    df = df.copy()\n",
    "    if label_col not in df.columns:\n",
    "        raise KeyError(f\"label_col {label_col} not in DataFrame\")\n",
    "\n",
    "    y_counts = Counter(df[label_col])\n",
    "    if minority_label not in y_counts:\n",
    "        raise ValueError(f\"Minority label {minority_label} not found in label column. Can't oversample from nothing.\")\n",
    "\n",
    "    majority_label = max(y_counts, key=lambda k: y_counts[k])\n",
    "    minority_count = y_counts[minority_label]\n",
    "    majority_count = y_counts[majority_label]\n",
    "\n",
    "    # compute desired minority count\n",
    "    if target_type == 'ratio':\n",
    "        if not (0 < target):\n",
    "            raise ValueError(\"For ratio, target must be > 0 (e.g. 0.5 means minority = 50% of majority).\")\n",
    "        desired_minority = int(np.round(target * majority_count))\n",
    "    elif target_type == 'absolute':\n",
    "        if int(target) <= 0:\n",
    "            raise ValueError(\"Absolute target must be positive.\")\n",
    "        desired_minority = int(target)\n",
    "    else:\n",
    "        raise ValueError(\"target_type must be 'ratio' or 'absolute'.\")\n",
    "\n",
    "    # do nothing if already enough\n",
    "    if minority_count >= desired_minority:\n",
    "        return df.reset_index(drop=True)\n",
    "\n",
    "    # prepare X, y\n",
    "    X = df.drop(columns=[label_col])\n",
    "    y = df[label_col]\n",
    "\n",
    "    samples_needed = desired_minority - minority_count\n",
    "\n",
    "    # Try SMOTE when allowed and feasible\n",
    "    if use_smote and minority_count >= (smote_k_neighbors + 1):\n",
    "        sampling_strategy = {minority_label: desired_minority}\n",
    "        sm = SMOTE(sampling_strategy=sampling_strategy, random_state=random_state, k_neighbors=smote_k_neighbors)\n",
    "        X_res, y_res = sm.fit_resample(X, y)\n",
    "        df_res = pd.concat([X_res, y_res], axis=1)\n",
    "        return df_res.reset_index(drop=True)\n",
    "\n",
    "    # Otherwise use RandomOverSampler to reach the desired minority count, then add Gaussian noise\n",
    "    sampling_strategy = {minority_label: desired_minority}\n",
    "    ros = RandomOverSampler(sampling_strategy=sampling_strategy, random_state=random_state)\n",
    "    X_res, y_res = ros.fit_resample(X, y)\n",
    "\n",
    "    # Add noise only to numeric columns\n",
    "    numeric_cols = X_res.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    if len(numeric_cols) == 0:\n",
    "        # nothing numeric to perturb; return as-is\n",
    "        df_res = pd.concat([X_res, y_res], axis=1)\n",
    "        return df_res.reset_index(drop=True)\n",
    "\n",
    "    # Need to add noise only to the newly created rows for the minority class.\n",
    "    # RandomOverSampler appends new samples but ordering is not strictly guaranteed across implementations,\n",
    "    # so we'll locate rows where label == minority and that were not in original indices.\n",
    "    # Simpler and safe approach: compute how many minority rows were originally present, then perturb that\n",
    "    # many of the minority rows *beyond the first minority_count* occurrences.\n",
    "    minority_indices = np.flatnonzero((y_res.values == minority_label))\n",
    "    # the first minority_count occurrences may correspond to original minority examples, so perturb the tail.\n",
    "    # But to be safe (when order unknown), we'll pick `samples_needed` indices from the minority_indices,\n",
    "    # preferring those with duplicated rows compared to original set.\n",
    "    # We'll find rows in X_res that exactly match any original minority row â€” mark them as originals.\n",
    "    original_minority_df = X[y == minority_label].reset_index(drop=True)\n",
    "    # Build a boolean mask whether a row in X_res matches any original minority row (fast-ish via tuple matching)\n",
    "    orig_tuples = set(map(tuple, original_minority_df[numeric_cols].fillna(0).values))\n",
    "    rows_to_perturb = []\n",
    "    for i, row in enumerate(X_res[numeric_cols].fillna(0).values):\n",
    "        if y_res.iloc[i] != minority_label:\n",
    "            continue\n",
    "        tup = tuple(row)\n",
    "        if tup not in orig_tuples:\n",
    "            rows_to_perturb.append(i)\n",
    "    # if we didn't find enough \"new\" rows by exact matching (rare), pick from minority_indices tail\n",
    "    if len(rows_to_perturb) < samples_needed:\n",
    "        # choose from minority_indices the last samples_needed indexes that are not in rows_to_perturb\n",
    "        extras = [int(i) for i in minority_indices if int(i) not in rows_to_perturb]\n",
    "        # take from the end (these are likely the duplicated ones)\n",
    "        take = extras[-samples_needed:]\n",
    "        rows_to_perturb = (rows_to_perturb + take)[-samples_needed:]\n",
    "\n",
    "    rows_to_perturb = rows_to_perturb[:samples_needed]\n",
    "\n",
    "    # compute stds on original data (avoid influence from synthetic data)\n",
    "    per_feature_stds = X[numeric_cols].std().replace(0, 1.0)  # avoid zero std\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    rows_to_perturb = np.asarray(rows_to_perturb, dtype=int)\n",
    "    \n",
    "    # Generate noise for *all* rows at once\n",
    "    noise_matrix = rng.normal(\n",
    "        loc=0.0,\n",
    "        scale=(per_feature_stds * noise_scale).values,\n",
    "        size=(len(rows_to_perturb), len(numeric_cols))\n",
    "    )\n",
    "    \n",
    "    # Add noise in one assignment (no copy, no SettingWithCopyWarning)\n",
    "    X_res.loc[X_res.index[rows_to_perturb], numeric_cols] += noise_matrix\n",
    "\n",
    "    df_res = pd.concat([X_res, y_res], axis=1)\n",
    "    return df_res.reset_index(drop=True)\n",
    "\n",
    "\n",
    "oversample_with_noise(\n",
    "    test_segmented['AAAACT'],\n",
    "    'label',\n",
    "    minority_label=1,\n",
    "    target=0.1,\n",
    "    target_type='ratio',   # 'ratio' or 'absolute'\n",
    "    noise_scale=0.02,      # proportion of feature std for noise\n",
    "    random_state=42,\n",
    "    use_smote=True,\n",
    "    smote_k_neighbors=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9d72dced-2792-4698-b086-4bdd5c9a5baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_actual_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "22ebd6c0-05a5-4eb6-a006-2752cfd68340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total:87350\n",
      "Pred:87350\n"
     ]
    }
   ],
   "source": [
    "print(\"Total:\"+str(sum(map(len,val_segmented.values()))))\n",
    "print(\"Pred:\"+str(len(filter_y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a3cc18-c19c-4feb-b6b9-002dfed93a49",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "0b8c20af-4c68-4cfc-993b-ae37b98eea5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.5631527387114106\n",
      "PR AUC: 0.084635562249819\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "\n",
    "\n",
    "# ROC AUC\n",
    "roc_auc = roc_auc_score(filter_y_actual, filter_y_pred)\n",
    "\n",
    "# PR AUC (Average Precision)\n",
    "pr_auc = average_precision_score(filter_y_actual, filter_y_pred)\n",
    "\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "print(\"PR AUC:\", pr_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2d8f6e9f-1219-4b44-864f-4a3f06dfea64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24274"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_pred>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1d26e5e0-e76b-480e-83d5-96285adf425d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17596"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_h = np.array([])\n",
    "y_h = np.append(y_h, post_middle[:,2])\n",
    "y_h = np.append(y_h, post_middle[:,2])\n",
    "\n",
    "len(y_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5be23675-140b-4ce6-8f5c-3be4a352e8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall mean proportion = 0.04886430397945919\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQ</th>\n",
       "      <th>positive_label</th>\n",
       "      <th>total</th>\n",
       "      <th>prop</th>\n",
       "      <th>p_value</th>\n",
       "      <th>p_fdr</th>\n",
       "      <th>p_bonferroni</th>\n",
       "      <th>prop_relative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAAACAA</td>\n",
       "      <td>62</td>\n",
       "      <td>115107</td>\n",
       "      <td>0.000539</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.011023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAAACAC</td>\n",
       "      <td>842</td>\n",
       "      <td>44283</td>\n",
       "      <td>0.019014</td>\n",
       "      <td>6.029589e-240</td>\n",
       "      <td>1.039833e-239</td>\n",
       "      <td>1.736522e-237</td>\n",
       "      <td>0.389120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAAACAG</td>\n",
       "      <td>487</td>\n",
       "      <td>54262</td>\n",
       "      <td>0.008975</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.183671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAAACAT</td>\n",
       "      <td>142</td>\n",
       "      <td>72284</td>\n",
       "      <td>0.001964</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.040203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAAACCA</td>\n",
       "      <td>93</td>\n",
       "      <td>64406</td>\n",
       "      <td>0.001444</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.029551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>TTGACCT</td>\n",
       "      <td>1011</td>\n",
       "      <td>50758</td>\n",
       "      <td>0.019918</td>\n",
       "      <td>1.037660e-255</td>\n",
       "      <td>1.915680e-255</td>\n",
       "      <td>2.988460e-253</td>\n",
       "      <td>0.407619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>TTGACTA</td>\n",
       "      <td>57</td>\n",
       "      <td>19329</td>\n",
       "      <td>0.002949</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.060350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>TTGACTC</td>\n",
       "      <td>1676</td>\n",
       "      <td>25420</td>\n",
       "      <td>0.065932</td>\n",
       "      <td>2.687902e-33</td>\n",
       "      <td>3.071888e-33</td>\n",
       "      <td>7.741158e-31</td>\n",
       "      <td>1.349295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>TTGACTG</td>\n",
       "      <td>4000</td>\n",
       "      <td>33458</td>\n",
       "      <td>0.119553</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.446630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>TTGACTT</td>\n",
       "      <td>1021</td>\n",
       "      <td>45845</td>\n",
       "      <td>0.022271</td>\n",
       "      <td>1.964933e-190</td>\n",
       "      <td>3.215346e-190</td>\n",
       "      <td>5.659008e-188</td>\n",
       "      <td>0.455766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         SEQ  positive_label   total      prop        p_value          p_fdr  \\\n",
       "0    AAAACAA              62  115107  0.000539   0.000000e+00   0.000000e+00   \n",
       "1    AAAACAC             842   44283  0.019014  6.029589e-240  1.039833e-239   \n",
       "2    AAAACAG             487   54262  0.008975   0.000000e+00   0.000000e+00   \n",
       "3    AAAACAT             142   72284  0.001964   0.000000e+00   0.000000e+00   \n",
       "4    AAAACCA              93   64406  0.001444   0.000000e+00   0.000000e+00   \n",
       "..       ...             ...     ...       ...            ...            ...   \n",
       "283  TTGACCT            1011   50758  0.019918  1.037660e-255  1.915680e-255   \n",
       "284  TTGACTA              57   19329  0.002949   0.000000e+00   0.000000e+00   \n",
       "285  TTGACTC            1676   25420  0.065932   2.687902e-33   3.071888e-33   \n",
       "286  TTGACTG            4000   33458  0.119553   0.000000e+00   0.000000e+00   \n",
       "287  TTGACTT            1021   45845  0.022271  1.964933e-190  3.215346e-190   \n",
       "\n",
       "      p_bonferroni  prop_relative  \n",
       "0     0.000000e+00       0.011023  \n",
       "1    1.736522e-237       0.389120  \n",
       "2     0.000000e+00       0.183671  \n",
       "3     0.000000e+00       0.040203  \n",
       "4     0.000000e+00       0.029551  \n",
       "..             ...            ...  \n",
       "283  2.988460e-253       0.407619  \n",
       "284   0.000000e+00       0.060350  \n",
       "285   7.741158e-31       1.349295  \n",
       "286   0.000000e+00       2.446630  \n",
       "287  5.659008e-188       0.455766  \n",
       "\n",
       "[288 rows x 8 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = (\n",
    "    train.groupby(\"SEQ\", as_index=False)\n",
    "      .agg(\n",
    "          positive_label=(\"label\", \"sum\"),\n",
    "          total=(\"label\", \"count\")\n",
    "      )\n",
    ")\n",
    "\n",
    "summary[\"prop\"] = summary[\"positive_label\"] / summary[\"total\"]\n",
    "\n",
    "overall_prop = summary[\"positive_label\"].sum() / summary[\"total\"].sum()\n",
    "\n",
    "from scipy.stats import binomtest\n",
    "\n",
    "summary[\"p_value\"] = summary.apply(\n",
    "    lambda row: binomtest(\n",
    "        row[\"positive_label\"], \n",
    "        row[\"total\"], \n",
    "        overall_prop, \n",
    "        alternative='two-sided'\n",
    "    ).pvalue,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "\n",
    "# Step 4: Multiple testing correction\n",
    "summary[\"p_fdr\"] = multipletests(summary[\"p_value\"], method=\"fdr_bh\")[1]\n",
    "summary[\"p_bonferroni\"] = multipletests(summary[\"p_value\"], method=\"bonferroni\")[1]\n",
    "\n",
    "summary['prop_relative'] = summary.apply(\n",
    "\n",
    "    lambda row: row['prop']/overall_prop,\n",
    "    axis = 1\n",
    "    \n",
    ")\n",
    "print(\"Overall mean proportion =\", overall_prop)\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8ad651-fb1c-4755-a746-bc4157429f9d",
   "metadata": {},
   "source": [
    "### Filtering away insufficient data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "57a6025f-a7e0-444b-8c35-75d3d3c47326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22     AAGACTG\n",
       "34     AGAACTG\n",
       "45     AGGACTC\n",
       "46     AGGACTG\n",
       "47     AGGACTT\n",
       "116    CGGACTA\n",
       "117    CGGACTC\n",
       "118    CGGACTG\n",
       "119    CGGACTT\n",
       "189    GGGACTC\n",
       "190    GGGACTG\n",
       "191    GGGACTT\n",
       "261    TGGACTC\n",
       "262    TGGACTG\n",
       "263    TGGACTT\n",
       "Name: SEQ, dtype: object"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10 = summary[summary[\"prop\"] >= summary[\"prop\"].quantile(0.95)]\n",
    "top10['SEQ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6f9cf0b2-f3a1-4cc1-8ff8-1ef7e4262d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQ</th>\n",
       "      <th>positive_label</th>\n",
       "      <th>total</th>\n",
       "      <th>prop</th>\n",
       "      <th>p_value</th>\n",
       "      <th>p_fdr</th>\n",
       "      <th>p_bonferroni</th>\n",
       "      <th>prop_relative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAAACAA</td>\n",
       "      <td>62</td>\n",
       "      <td>115107</td>\n",
       "      <td>0.000539</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.011023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAAACAC</td>\n",
       "      <td>842</td>\n",
       "      <td>44283</td>\n",
       "      <td>0.019014</td>\n",
       "      <td>6.029589e-240</td>\n",
       "      <td>1.039833e-239</td>\n",
       "      <td>1.736522e-237</td>\n",
       "      <td>0.389120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAAACAG</td>\n",
       "      <td>487</td>\n",
       "      <td>54262</td>\n",
       "      <td>0.008975</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.183671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAAACAT</td>\n",
       "      <td>142</td>\n",
       "      <td>72284</td>\n",
       "      <td>0.001964</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.040203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAAACCA</td>\n",
       "      <td>93</td>\n",
       "      <td>64406</td>\n",
       "      <td>0.001444</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.029551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>TTGACCT</td>\n",
       "      <td>1011</td>\n",
       "      <td>50758</td>\n",
       "      <td>0.019918</td>\n",
       "      <td>1.037660e-255</td>\n",
       "      <td>1.915680e-255</td>\n",
       "      <td>2.988460e-253</td>\n",
       "      <td>0.407619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>TTGACTA</td>\n",
       "      <td>57</td>\n",
       "      <td>19329</td>\n",
       "      <td>0.002949</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.060350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>TTGACTC</td>\n",
       "      <td>1676</td>\n",
       "      <td>25420</td>\n",
       "      <td>0.065932</td>\n",
       "      <td>2.687902e-33</td>\n",
       "      <td>3.071888e-33</td>\n",
       "      <td>7.741158e-31</td>\n",
       "      <td>1.349295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>TTGACTG</td>\n",
       "      <td>4000</td>\n",
       "      <td>33458</td>\n",
       "      <td>0.119553</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.446630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>TTGACTT</td>\n",
       "      <td>1021</td>\n",
       "      <td>45845</td>\n",
       "      <td>0.022271</td>\n",
       "      <td>1.964933e-190</td>\n",
       "      <td>3.215346e-190</td>\n",
       "      <td>5.659008e-188</td>\n",
       "      <td>0.455766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         SEQ  positive_label   total      prop        p_value          p_fdr  \\\n",
       "0    AAAACAA              62  115107  0.000539   0.000000e+00   0.000000e+00   \n",
       "1    AAAACAC             842   44283  0.019014  6.029589e-240  1.039833e-239   \n",
       "2    AAAACAG             487   54262  0.008975   0.000000e+00   0.000000e+00   \n",
       "3    AAAACAT             142   72284  0.001964   0.000000e+00   0.000000e+00   \n",
       "4    AAAACCA              93   64406  0.001444   0.000000e+00   0.000000e+00   \n",
       "..       ...             ...     ...       ...            ...            ...   \n",
       "283  TTGACCT            1011   50758  0.019918  1.037660e-255  1.915680e-255   \n",
       "284  TTGACTA              57   19329  0.002949   0.000000e+00   0.000000e+00   \n",
       "285  TTGACTC            1676   25420  0.065932   2.687902e-33   3.071888e-33   \n",
       "286  TTGACTG            4000   33458  0.119553   0.000000e+00   0.000000e+00   \n",
       "287  TTGACTT            1021   45845  0.022271  1.964933e-190  3.215346e-190   \n",
       "\n",
       "      p_bonferroni  prop_relative  \n",
       "0     0.000000e+00       0.011023  \n",
       "1    1.736522e-237       0.389120  \n",
       "2     0.000000e+00       0.183671  \n",
       "3     0.000000e+00       0.040203  \n",
       "4     0.000000e+00       0.029551  \n",
       "..             ...            ...  \n",
       "283  2.988460e-253       0.407619  \n",
       "284   0.000000e+00       0.060350  \n",
       "285   7.741158e-31       1.349295  \n",
       "286   0.000000e+00       2.446630  \n",
       "287  5.659008e-188       0.455766  \n",
       "\n",
       "[288 rows x 8 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f91b1f6-5316-40de-b744-b22e0f9a425c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[2.99e-03 2.06e+00 1.25e+02]\n",
      "  [1.77e-02 1.04e+01 1.22e+02]\n",
      "  [9.30e-03 1.09e+01 8.41e+01]]\n",
      "\n",
      " [[6.31e-03 2.53e+00 1.25e+02]\n",
      "  [8.44e-03 4.67e+00 1.26e+02]\n",
      "  [1.03e-02 6.30e+00 8.09e+01]]\n",
      "\n",
      " [[4.65e-03 3.92e+00 1.09e+02]\n",
      "  [1.36e-02 1.20e+01 1.24e+02]\n",
      "  [4.98e-03 2.13e+00 7.96e+01]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[7.21e-03 4.58e+00 1.05e+02]\n",
      "  [3.98e-03 6.58e+00 1.13e+02]\n",
      "  [3.16e-03 2.28e+00 8.53e+01]]\n",
      "\n",
      " [[2.66e-03 2.33e+00 1.09e+02]\n",
      "  [9.13e-03 1.04e+01 1.08e+02]\n",
      "  [6.64e-03 4.44e+00 7.68e+01]]\n",
      "\n",
      " [[5.64e-03 3.13e+00 1.10e+02]\n",
      "  [3.03e-03 9.98e+00 1.18e+02]\n",
      "  [1.93e-02 1.79e+00 7.62e+01]]]\n",
      "[[0 1 3]\n",
      " [0 1 3]\n",
      " [0 1 3]\n",
      " ...\n",
      " [0 1 3]\n",
      " [0 1 3]\n",
      " [0 1 3]]\n"
     ]
    }
   ],
   "source": [
    "X_train = train[['PreTime', 'PreSD', 'PreMean', \n",
    "               'InTime', 'InSD', 'InMean', \n",
    "               'PostTime', 'PostSD', 'PostMean']].to_numpy().reshape(-1,3,3)\n",
    "\n",
    "y_train = np.column_stack([\n",
    "    np.zeros(len(train), dtype=int),\n",
    "    train['label'].to_numpy() + 1,\n",
    "    np.full(len(train), 3, dtype=int)\n",
    "])\n",
    "\n",
    "print(X_train)\n",
    "print(y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "056e5fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 0. Imports & Setup\n",
    "# =========================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import pickle\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "import os, re\n",
    "\n",
    "\n",
    "# Reproducibility\n",
    "RNG = 42\n",
    "np.random.seed(RNG)\n",
    "torch.manual_seed(RNG)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870725c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 1. Load and Preparing datasets\n",
    "# =========================\n",
    "print(\"Starting: 1. Load and Prepare datasets\")\n",
    "reads_df = pd.read_csv(\"Raw File/dataset0.csv\")\n",
    "\n",
    "columns_to_drop = ['Unnamed: 0']\n",
    "reads_df = reads_df.drop(columns_to_drop, axis=1, errors='ignore')\n",
    "\n",
    "# sorry cherron i cannot with the colnames\n",
    "reads_df = reads_df.rename(columns={\n",
    "    'ID': 'transcript_id',\n",
    "    'POS': 'transcript_position',\n",
    "    'SEQ': '7mer'\n",
    "})\n",
    "reads_df['n_reads'] = reads_df.groupby(['transcript_id', 'transcript_position']).transform('size')\n",
    "\n",
    "\n",
    "print(\"Ending: 1. Load and Prepare datasets\")\n",
    "# =========================\n",
    "# 2. Preprocessing: 7-mer embedding\n",
    "# =========================\n",
    "print(\"Starting: 2. Preprocessing: 7-mer embedding\")\n",
    "\n",
    "def encode_drach_compact(seq):\n",
    "    \"\"\"\n",
    "    Compact one-hot encoding of a 7-mer centered on a DRACH motif.\n",
    "    Positions:\n",
    "    - 0: full one-hot (A,C,G,T) â†’ 4 dims\n",
    "    - 1: D (A,G,T) â†’ 3 dims\n",
    "    - 2: R (A,G)   â†’ 2 dims\n",
    "    - 3: A (fixed) â†’ 0 dims\n",
    "    - 4: C (fixed) â†’ 0 dims\n",
    "    - 5: H (A,C,T) â†’ 3 dims\n",
    "    - 6: full one-hot (A,C,G,T) â†’ 4 dims\n",
    "    Total: 16-dimensional vector\n",
    "    \"\"\"\n",
    "    encoding = []\n",
    "\n",
    "    base = seq[0]\n",
    "    encoding.extend(one_hot_base(base, ['A', 'C', 'G', 'T']))\n",
    "\n",
    "    base = seq[1]\n",
    "    encoding.extend(one_hot_base(base, ['A', 'G', 'T']))  # D\n",
    "\n",
    "    base = seq[2]\n",
    "    encoding.extend(one_hot_base(base, ['A', 'G']))       # R\n",
    "\n",
    "    # skip position 3 (always A)\n",
    "    # skip position 4 (always C)\n",
    "\n",
    "    base = seq[5]\n",
    "    encoding.extend(one_hot_base(base, ['A', 'C', 'T']))  # H\n",
    "\n",
    "    base = seq[6]\n",
    "    encoding.extend(one_hot_base(base, ['A', 'C', 'G', 'T']))\n",
    "\n",
    "    return np.array(encoding, dtype=np.float32)\n",
    "\n",
    "def one_hot_base(base, allowed):\n",
    "    \"\"\"One-hot encode base using only allowed bases.\"\"\"\n",
    "    vec = [0] * len(allowed)\n",
    "    if base in allowed:\n",
    "        vec[allowed.index(base)] = 1\n",
    "    return vec\n",
    "\n",
    "reads_df['7mer_emb'] = reads_df['7mer'].apply(encode_drach_compact)\n",
    "print(\"Ending: 2. Preprocessing: 7-mer embedding\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 3. Assign split bins\n",
    "# =========================\n",
    "print(\"Starting: 3. Assign split bins\")\n",
    "\n",
    "def assign_set_type_by_gene(reads_df, split_ratios={'Train': 0.8, 'Val': 0.1, 'Test': 0.1}, random_state=42):\n",
    "    \"\"\"\n",
    "    Assigns each row in reads_df a 'set_type' of Train, Val, or Test,\n",
    "    ensuring all rows with the same gene_id are in the same set,\n",
    "    and total number of rows (not just genes) in each set matches desired ratios.\n",
    "    Label distribution is approximately balanced using a greedy strategy.\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1: Get stats per gene\n",
    "    gene_stats = (\n",
    "        reads_df\n",
    "        .groupby('gene_id')['label']\n",
    "        .value_counts()\n",
    "        .unstack(fill_value=0)\n",
    "        .rename(columns={0: 'label_0', 1: 'label_1'})\n",
    "        .reset_index()\n",
    "    )\n",
    "    gene_stats['total'] = gene_stats['label_0'] + gene_stats['label_1']\n",
    "\n",
    "    # Shuffle genes for randomness\n",
    "    gene_stats = gene_stats.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "\n",
    "    # Step 2: Overall label distribution and target row counts\n",
    "    total_rows = gene_stats['total'].sum()\n",
    "    total_label_1 = gene_stats['label_1'].sum()\n",
    "    overall_pos_rate = total_label_1 / total_rows\n",
    "\n",
    "    target_rows = {k: total_rows * split_ratios[k] for k in split_ratios}\n",
    "\n",
    "    # Step 3: Initialize bins\n",
    "    bins = {\n",
    "        'Train': {'genes': [], 'label_0': 0, 'label_1': 0, 'total': 0},\n",
    "        'Val': {'genes': [], 'label_0': 0, 'label_1': 0, 'total': 0},\n",
    "        'Test': {'genes': [], 'label_0': 0, 'label_1': 0, 'total': 0},\n",
    "    }\n",
    "\n",
    "    def pick_bin():\n",
    "        # Find the bin with the biggest gap between current and target row count\n",
    "        diffs = {k: target_rows[k] - bins[k]['total'] for k in bins}\n",
    "        # Choose the bin that needs rows the most\n",
    "        return max(diffs, key=diffs.get)\n",
    "\n",
    "    # Step 4: Assign genes to bins to match row targets and label balance\n",
    "    for _, row in gene_stats.iterrows():\n",
    "        chosen_bin = pick_bin()\n",
    "        bins[chosen_bin]['genes'].append(row['gene_id'])\n",
    "        bins[chosen_bin]['label_0'] += row['label_0']\n",
    "        bins[chosen_bin]['label_1'] += row['label_1']\n",
    "        bins[chosen_bin]['total'] += row['total']\n",
    "\n",
    "    # Step 5: Map gene_id â†’ set_type\n",
    "    gene_to_set = {}\n",
    "    for set_name, bin_data in bins.items():\n",
    "        for gene_id in bin_data['genes']:\n",
    "            gene_to_set[gene_id] = set_name\n",
    "\n",
    "    reads_df['set_type'] = reads_df['gene_id'].map(gene_to_set)\n",
    "\n",
    "    return reads_df\n",
    "\n",
    "\n",
    "reads_df = assign_set_type_by_gene(reads_df)\n",
    "\n",
    "set_counts = reads_df['set_type'].value_counts()\n",
    "print(\"ðŸ“Š Number of rows in each set:\")\n",
    "for set_name, count in set_counts.items():\n",
    "    print(f\"  - {set_name}: {count} rows\")\n",
    "\n",
    "# Print label distribution per set (normalized)\n",
    "label_distributions = reads_df.groupby('set_type')['label'].value_counts(normalize=True).unstack()\n",
    "\n",
    "print(\"\\nðŸ“ˆ Label distribution (percentage of label 0 and 1) in each set:\")\n",
    "for set_name in label_distributions.index:\n",
    "    label_0_pct = label_distributions.loc[set_name].get(0, 0) * 100\n",
    "    label_1_pct = label_distributions.loc[set_name].get(1, 0) * 100\n",
    "    print(f\"  - {set_name}:\")\n",
    "    print(f\"      â€¢ Label 0: {label_0_pct:.2f}%\")\n",
    "    print(f\"      â€¢ Label 1: {label_1_pct:.2f}%\")\n",
    "\n",
    "print(\"Ending: 3. Assign split bins\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01da9f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Column Data Types:\")\n",
    "# print(reads_df.dtypes)\n",
    "\n",
    "# # Display the number of rows\n",
    "# print(\"\\nNumber of Rows:\", len(reads_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8e7ca5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = \"Dataset/\"\n",
    "# file_name = \"processed_dataset.parquet\"\n",
    "# reads_df.to_parquet(f\"{file_path}{file_name}\", index=False)\n",
    "# print(f\"Saved processed dataset to {file_path}{file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcacdec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting: 4. Dataset class\n",
      "Ending: 4. Dataset class\n",
      "Starting: 5. Samplers and Collate\n",
      "Ending: 5. Samplers and Collate\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 4. Dataset class\n",
    "# =========================\n",
    "print(\"Starting: 4. Dataset class\")\n",
    "class MILReadDataset(Dataset):\n",
    "    def __init__(self, reads_df, n_reads_per_site=None, agg_config=None):\n",
    "        \"\"\"\n",
    "        reads_df: DataFrame with read-level rows:\n",
    "                  ['transcript_id','transcript_position','7mer_emb','label',\n",
    "                   'PreTime','PreSD','PreMean','InTime','InSD','InMean','PostTime','PostSD','PostMean',...]\n",
    "        n_reads_per_site: int or None\n",
    "            - int: sample at most this many reads per site\n",
    "            - None: use all reads\n",
    "        agg_config: dict for aggregation at site level, e.g.\n",
    "            {\n",
    "              \"Time\": [\"min\",\"max\",\"mean\",\"25\",\"75\"],\n",
    "              \"SD\": [\"mean\"],\n",
    "              \"Mean\": [\"mean\"]\n",
    "            }\n",
    "        \"\"\"\n",
    "\n",
    "        self.n_reads_per_site = n_reads_per_site\n",
    "        self.groups = reads_df.groupby(['transcript_id', 'transcript_position'])\n",
    "        self.bags = list(self.groups.groups.keys())\n",
    "        self.reads_df = reads_df\n",
    "        # self.use_delta = True  # <--- toggle delta features on read levels\n",
    "\n",
    "        # -----------------------------\n",
    "        # Feature toggle switches\n",
    "        # -----------------------------\n",
    "        # Comment/uncomment entries to include/exclude features\n",
    "        self.read_feature_flags = {\n",
    "            \"numeric\": True,   # PreTime..PostMean\n",
    "            \"7mer\": True,      # 7mer embedding at read-level\n",
    "            \"delta\": True,\n",
    "        }\n",
    "        self.site_feature_flags = {\n",
    "            \"numeric_aggs\": True,  # aggregated Time/SD/Mean stats\n",
    "            \"7mer\": True,          # site-level 7mer embedding\n",
    "        }\n",
    "\n",
    "        # Default aggregation if not passed\n",
    "        self.agg_config = agg_config or {\n",
    "            \"Time\": [\"min\", \"max\", \"mean\", \"25\", \"75\"],\n",
    "            \"SD\": [\"mean\"],\n",
    "            \"Mean\": [\"mean\"]\n",
    "        }\n",
    "\n",
    "        # Bag lengths\n",
    "        self.bag_lengths = {k: len(v) for k, v in self.groups}\n",
    "\n",
    "        # Labels\n",
    "        self.bag_labels = {}\n",
    "        for k in self.bags:\n",
    "            g = self.groups.get_group(k)\n",
    "            self.bag_labels[k] = int(g['label'].iloc[0])\n",
    "\n",
    "        # -----------------------------\n",
    "        # Infer dimensions\n",
    "        # -----------------------------\n",
    "        dummy_bag = self[0]\n",
    "        _, _, _, _, _ = dummy_bag\n",
    "        print(f\"âœ… Dataset initialized: read_dim = {self.read_dim}, site_dim = {self.site_dim}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.bags)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tid, pos = self.bags[idx]\n",
    "        g = self.groups.get_group((tid, pos))\n",
    "\n",
    "        # -----------------------------\n",
    "        # Read-level matrix\n",
    "        # -----------------------------\n",
    "        read_parts = []\n",
    "\n",
    "        if self.read_feature_flags[\"numeric\"]:\n",
    "            numeric_feats = g[[\n",
    "                'PreTime','PreSD','PreMean',\n",
    "                'InTime','InSD','InMean',\n",
    "                'PostTime','PostSD','PostMean'\n",
    "            ]].values.astype(np.float32)\n",
    "            read_parts.append(numeric_feats)\n",
    "\n",
    "        if self.read_feature_flags[\"7mer\"]:\n",
    "            kmer_list = list(g['7mer_emb'].values)\n",
    "            kmer_emb_read = np.vstack(kmer_list).astype(np.float32)\n",
    "            read_parts.append(kmer_emb_read)\n",
    "\n",
    "\n",
    "        if self.read_feature_flags[\"delta\"]:\n",
    "            deltas = []\n",
    "            # Time deltas\n",
    "            deltas.append(numeric_feats[:, 3] - numeric_feats[:, 0])  # InTime - PreTime\n",
    "            deltas.append(numeric_feats[:, 6] - numeric_feats[:, 3])  # PostTime - InTime\n",
    "            # SD deltas\n",
    "            deltas.append(numeric_feats[:, 4] - numeric_feats[:, 1])  # InSD - PreSD\n",
    "            deltas.append(numeric_feats[:, 7] - numeric_feats[:, 4])  # PostSD - InSD\n",
    "            # Mean deltas\n",
    "            deltas.append(numeric_feats[:, 5] - numeric_feats[:, 2])  # InMean - PreMean\n",
    "            deltas.append(numeric_feats[:, 8] - numeric_feats[:, 5])  # PostMean - InMean\n",
    "\n",
    "            delta_feats = np.stack(deltas, axis=1)  # shape (n_reads, 6)\n",
    "            read_parts.append(delta_feats)\n",
    "        \n",
    "        bag_read_level = np.concatenate(read_parts, axis=1)\n",
    "\n",
    "        # Random subsampling\n",
    "        if self.n_reads_per_site is not None and bag_read_level.shape[0] > self.n_reads_per_site:\n",
    "            idxs = np.random.choice(bag_read_level.shape[0], self.n_reads_per_site, replace=False)\n",
    "            bag_read_level = bag_read_level[idxs]\n",
    "\n",
    "        # -----------------------------\n",
    "        # Site-level vector\n",
    "        # -----------------------------\n",
    "        site_parts = []\n",
    "\n",
    "        if self.site_feature_flags[\"numeric_aggs\"]:\n",
    "            site_aggs = []\n",
    "            groups = {\"Time\": [0, 3, 6], \"SD\": [1, 4, 7], \"Mean\": [2, 5, 8]}\n",
    "            for feat_type, idx_list in groups.items():\n",
    "                stats = self.agg_config.get(feat_type, [])\n",
    "                for col_idx in idx_list:\n",
    "                    vals = numeric_feats[:, col_idx].astype(np.float32)\n",
    "                    for stat in stats:\n",
    "                        if stat == \"min\": site_aggs.append(np.min(vals))\n",
    "                        elif stat == \"max\": site_aggs.append(np.max(vals))\n",
    "                        elif stat == \"mean\": site_aggs.append(np.mean(vals))\n",
    "                        elif stat == \"25\": site_aggs.append(np.percentile(vals, 25))\n",
    "                        elif stat == \"75\": site_aggs.append(np.percentile(vals, 75))\n",
    "            site_parts.append(np.array(site_aggs, dtype=np.float32))\n",
    "\n",
    "        if self.site_feature_flags[\"7mer\"]:\n",
    "            first_kmer = np.asarray(g['7mer_emb'].iloc[0], dtype=np.float32).ravel()\n",
    "            site_parts.append(first_kmer)\n",
    "            \n",
    "\n",
    "        bag_site_level = np.concatenate(site_parts, axis=0).astype(np.float32)\n",
    "\n",
    "        # -----------------------------\n",
    "        # Label + bookkeeping\n",
    "        # -----------------------------\n",
    "        label = int(g['label'].iloc[0])\n",
    "\n",
    "        # Store dims once (for printing at init)\n",
    "        if not hasattr(self, \"read_dim\"):\n",
    "            self.read_dim = bag_read_level.shape[1]\n",
    "            self.site_dim = bag_site_level.shape[0]\n",
    "            print(f\"Read-level dim: {self.read_dim} | Site-level dim: {self.site_dim}\")\n",
    "\n",
    "        return (torch.tensor(bag_read_level, dtype=torch.float32),\n",
    "                torch.tensor(bag_site_level, dtype=torch.float32),\n",
    "                torch.tensor(label, dtype=torch.float32),\n",
    "                tid, pos)\n",
    "\n",
    "    \n",
    "print(\"Ending: 4. Dataset class\")\n",
    "\n",
    "# =========================\n",
    "# 5. Imbalanced sampler\n",
    "# =========================\n",
    "print(\"Starting: 5. Samplers and Collate\")\n",
    "class ImbalancedBagSampler(Sampler):\n",
    "    \"\"\"\n",
    "    Oversamples positive bags to balance classes, with rebalancing every epoch.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, pos_neg_ratio=1.0):\n",
    "        \"\"\"\n",
    "        dataset: your MILReadDataset\n",
    "        balance_ratio: ratio of positive to negative samples after oversampling.\n",
    "                       - 1.0 = fully balanced (default)\n",
    "                       - 0.5 = positives are half as many as negatives\n",
    "                       - >1.0 = more positives than negatives\n",
    "        \"\"\"\n",
    "        self.dataset = dataset\n",
    "        self.pos_neg_ratio = pos_neg_ratio\n",
    "        # Pre-cache labels to avoid repeated dataset access\n",
    "        self.bags = self.dataset.bags\n",
    "        self.labels = np.array([self.dataset.bag_labels[k] for k in self.bags], dtype=np.int64)\n",
    "        self.pos_idx = np.where(self.labels == 1)[0]\n",
    "        self.neg_idx = np.where(self.labels == 0)[0]\n",
    "\n",
    "        if len(self.pos_idx) == 0:\n",
    "            raise ValueError(\"No positive bags found in dataset; pos_neg_ratio sampling not possible.\")\n",
    "        \n",
    "    def sample_indices(self):\n",
    "        n_pos_target = int(len(self.neg_idx) * self.pos_neg_ratio)\n",
    "        sampled_pos = np.random.choice(self.pos_idx, size=n_pos_target, replace=True)\n",
    "        combined = np.concatenate([self.neg_idx, sampled_pos])\n",
    "        np.random.shuffle(combined)\n",
    "        return combined\n",
    "    def __iter__(self):\n",
    "        return iter(self.sample_indices())\n",
    "\n",
    "    def __len__(self):\n",
    "        # length in terms of number of sampled bag indices\n",
    "        return len(self.neg_idx) + int(len(self.neg_idx) * self.pos_neg_ratio)\n",
    "    \n",
    "class BucketBatchSampler(Sampler):\n",
    "    \"\"\"\n",
    "    Groups bags of similar lengths (based on n_reads) into buckets,\n",
    "    shuffles bucket order each epoch, and yields random batches.\n",
    "    Please at the least set bucket_size value to be multiple of batch_size\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, base_sampler, batch_size=4, bucket_size=200):\n",
    "        self.dataset = dataset\n",
    "        self.base_sampler = base_sampler\n",
    "        self.batch_size = batch_size\n",
    "        self.bucket_size = bucket_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        # Get sampled indices from ImbalancedBagSampler\n",
    "        indices = self.base_sampler.sample_indices()\n",
    "        lengths = np.array([self.dataset.bag_lengths[self.dataset.bags[i]] for i in indices])\n",
    "        sorted_idx = indices[np.argsort(lengths)]\n",
    "\n",
    "        # Split into buckets of similar lengths\n",
    "        buckets = [sorted_idx[i:i+self.bucket_size] for i in range(0, len(sorted_idx), self.bucket_size)]\n",
    "        np.random.shuffle(buckets)\n",
    "\n",
    "        lst_of_batch = []\n",
    "        for bucket in buckets:\n",
    "            np.random.shuffle(bucket)\n",
    "            for i in range(0, len(bucket), self.batch_size):\n",
    "                batch = bucket[i:i+self.batch_size]\n",
    "                lst_of_batch.append(batch)\n",
    "        np.random.shuffle(lst_of_batch)\n",
    "\n",
    "        for batch in lst_of_batch:\n",
    "            yield batch.tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        total = len(self.base_sampler.neg_idx) + int(len(self.base_sampler.neg_idx) * self.base_sampler.pos_neg_ratio)\n",
    "        return max(1, total // self.batch_size)\n",
    "\n",
    "# Collate function for minimal padding\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    batch: list of tuples (bag_read_level, bag_site_level, label, tid, pos)\n",
    "    returns:\n",
    "      padded_feats: (B, max_len, feat_dim)\n",
    "      site_level_tensor: (B, site_dim)\n",
    "      labels: (B,)\n",
    "      tids, positions: lists\n",
    "    \"\"\"\n",
    "    bag_read_level_list, bag_site_level_list, labels, tids, positions = zip(*batch)\n",
    "    \n",
    "    # pad read-level bags\n",
    "    max_len = max(x.shape[0] for x in bag_read_level_list)\n",
    "    feat_dim = bag_read_level_list[0].shape[1]\n",
    "    padded_feats = torch.zeros(len(bag_read_level_list), max_len, feat_dim, dtype=torch.float32)\n",
    "    for i, nf in enumerate(bag_read_level_list):\n",
    "        padded_feats[i, :nf.shape[0], :] = nf\n",
    "\n",
    "    # stack site-level vectors (they must be same length across batch)\n",
    "    site_level_tensor = torch.stack([torch.as_tensor(x, dtype=torch.float32) for x in bag_site_level_list])\n",
    "\n",
    "    labels = torch.stack(labels)\n",
    "\n",
    "    return padded_feats, site_level_tensor, labels, tids, positions\n",
    "\n",
    "\n",
    "print(\"Ending: 5. Samplers and Collate\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a40d30af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting: 6. Split Train/Val/Test\n",
      "Loading in processed_dataset.parquet\n",
      "Read-level dim: 31 | Site-level dim: 37\n",
      "âœ… Dataset initialized: read_dim = 31, site_dim = 37\n",
      "Read-level dim: 31 | Site-level dim: 37\n",
      "âœ… Dataset initialized: read_dim = 31, site_dim = 37\n",
      "Read-level dim: 31 | Site-level dim: 37\n",
      "âœ… Dataset initialized: read_dim = 31, site_dim = 37\n",
      "Ending: 6. Split Train/Val/Test\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 6. Split Train/Val/Test\n",
    "# =========================\n",
    "print(\"Starting: 6. Split Train/Val/Test\")\n",
    "\n",
    "print(\"Loading in processed_dataset.parquet\")\n",
    "reads_df = pd.read_parquet(\"Dataset/processed_dataset.parquet\")\n",
    "\n",
    "# Now split by set_type\n",
    "train_df = reads_df[reads_df['set_type'] == 'Train']\n",
    "val_df   = reads_df[reads_df['set_type'] == 'Val']\n",
    "test_df  = reads_df[reads_df['set_type'] == 'Test']\n",
    "\n",
    "\n",
    "agg_config = { \"Time\": [\"min\", \"max\", \"mean\", \"25\", \"75\"]\n",
    "              , \"SD\": [\"mean\"]\n",
    "              , \"Mean\": [\"mean\"] \n",
    "              } \n",
    "\n",
    "train_ds = MILReadDataset(train_df, n_reads_per_site=20, agg_config=agg_config) \n",
    "val_ds = MILReadDataset(val_df, n_reads_per_site=20, agg_config=agg_config) \n",
    "test_ds = MILReadDataset(test_df, n_reads_per_site=20, agg_config=agg_config)\n",
    "\n",
    "#train_loader is inside Epoch Loop so as to randomise the positve bags that are oversampled\n",
    "val_loader   = DataLoader(val_ds, batch_size=1, shuffle=False)\n",
    "test_loader  = DataLoader(test_ds, batch_size=1, shuffle=False)\n",
    "print(\"Ending: 6. Split Train/Val/Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bea492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read-level dim: 31 | Site-level dim: 37\n",
      "âœ… Dataset initialized: read_dim = 31, site_dim = 37\n"
     ]
    }
   ],
   "source": [
    "# reads_df = pd.read_parquet(\"Dataset/processed_dataset.parquet\")\n",
    "\n",
    "\n",
    "# agg_config = { \"Time\": [\"min\", \"max\", \"mean\", \"25\", \"75\"]\n",
    "#               , \"SD\": [\"mean\"]\n",
    "#               , \"Mean\": [\"mean\"] \n",
    "#               } \n",
    "\n",
    "\n",
    "# test_ds = MILReadDataset(test_df, n_reads_per_site=20, agg_config=agg_config)\n",
    "# test_loader  = DataLoader(test_ds, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b42c7459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting: 7. Attention MIL Model\n",
      "Automatically detected read_dim=31, site_dim=37\n",
      "Ending: 7. Attention MIL Model\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 7. Attention MIL Model\n",
    "# =========================\n",
    "print(\"Starting: 7. Attention MIL Model\")\n",
    "class MultiHeadAttentionPool(nn.Module):\n",
    "    def __init__(self, hidden_dim, n_heads=4):\n",
    "        super().__init__()\n",
    "        self.n_heads = n_heads\n",
    "        # project to head space then scalar score per head\n",
    "        self.proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.head_score = nn.Linear(hidden_dim, n_heads)  # outputs (batch, n_instances, n_heads)\n",
    "    \n",
    "    def forward(self, H):  # H: (B, N, hidden_dim)\n",
    "        # Optionally nonlinearity\n",
    "        S = torch.tanh(self.proj(H))            # (B, N, hidden_dim)\n",
    "        scores = self.head_score(S)             # (B, N, n_heads)\n",
    "        attn = torch.softmax(scores, dim=1)     # softmax over instances per head\n",
    "        # attn: (B, N, n_heads). compute per-head pooled vectors:\n",
    "        # transpose H to (B, hidden_dim, N) to do matmul\n",
    "        pooled = []\n",
    "        for h in range(self.n_heads):\n",
    "            a = attn[..., h].unsqueeze(-1)      # (B, N, 1)\n",
    "            m = torch.sum(a * H, dim=1)         # (B, hidden_dim)\n",
    "            pooled.append(m)\n",
    "        # concat head outputs\n",
    "        M = torch.cat(pooled, dim=1)           # (B, hidden_dim * n_heads)\n",
    "        return M, attn                         # attn shape (B, N, n_heads)\n",
    "\n",
    "class AttentionMIL_v2(nn.Module):\n",
    "    def __init__(self, read_dim, site_dim, hidden_dim=128, n_heads=4, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.read_encoder = nn.Sequential(\n",
    "            nn.Linear(read_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self.site_encoder = nn.Sequential(\n",
    "            nn.Linear(site_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self.pool = MultiHeadAttentionPool(hidden_dim, n_heads=n_heads)\n",
    "        # project pooled concat (hidden_dim * n_heads) back to hidden_dim\n",
    "        self.pool_proj = nn.Linear(hidden_dim * n_heads, hidden_dim)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim*2, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, bag_read_level, bag_site_level):\n",
    "        # bag_read_level: (B,N,read_dim)\n",
    "        H = self.read_encoder(bag_read_level)   # (B,N,hidden_dim)\n",
    "        M_concat, attn = self.pool(H)           # (B, hidden_dim * n_heads)\n",
    "        M = self.pool_proj(M_concat)            # (B, hidden_dim)\n",
    "        site = self.site_encoder(bag_site_level) # (B, hidden_dim)\n",
    "        combined = torch.cat([M, site], dim=-1) # (B, hidden_dim*2)\n",
    "        out = self.classifier(combined).view(-1)\n",
    "        return out, attn\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1.0, gamma=2.0, reduction=\"mean\"):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        # BCE with logits\n",
    "        bce_loss = F.binary_cross_entropy_with_logits(\n",
    "            logits, targets.float(), reduction=\"none\"\n",
    "        )\n",
    "        # Get probabilities\n",
    "        probs = torch.sigmoid(logits)\n",
    "        pt = probs * targets + (1 - probs) * (1 - targets)  # p_t\n",
    "\n",
    "        # Focal loss factor\n",
    "        focal_factor = (1 - pt) ** self.gamma\n",
    "\n",
    "        # Apply alpha and focal scaling\n",
    "        loss = self.alpha * focal_factor * bce_loss\n",
    "\n",
    "        if self.reduction == \"mean\":\n",
    "            return loss.mean()\n",
    "        elif self.reduction == \"sum\":\n",
    "            return loss.sum()\n",
    "        else:\n",
    "            return loss\n",
    "        \n",
    "def predict_probs(model, bag_read_level, bag_site_level):\n",
    "    logits, attn = model(bag_read_level, bag_site_level)\n",
    "    return torch.sigmoid(logits), attn\n",
    "\n",
    "# --------------------------\n",
    "# Define model + optimizer\n",
    "# --------------------------\n",
    "# Get read and site dimensions from dataset\n",
    "read_dim = train_ds.read_dim\n",
    "site_dim = train_ds.site_dim\n",
    "\n",
    "print(f\"Automatically detected read_dim={read_dim}, site_dim={site_dim}\")\n",
    "\n",
    "# Initialize model using the inferred dimensions\n",
    "model = AttentionMIL_v2(read_dim=read_dim, site_dim=site_dim, hidden_dim=128, dropout=0.2).to(device)\n",
    "\n",
    "# change the lr to have higher penalisation\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "print(\"Ending: 7. Attention MIL Model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df8738e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting: 8. Training Loop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original positives: 4382.0, negatives: 91455.0\n",
      "Effective positives (oversampling 50%): 45727\n",
      "Epoch 1/300: TrainLoss=0.2333, ValROC-AUC=0.8882, ValPR-AUC=0.3790, EpochTime=336.47s,AvgTimePerBag=0.0490s\n",
      "Saved best model (ValPR-AUC improved to 0.3790) at epoch 1\n",
      "Epoch 2/300: TrainLoss=0.2147, ValROC-AUC=0.8900, ValPR-AUC=0.3676, EpochTime=364.28s,AvgTimePerBag=0.0531s\n",
      "No improvement in PR-AUC for 1 epoch(s).\n",
      "Epoch 3/300: TrainLoss=0.2096, ValROC-AUC=0.8883, ValPR-AUC=0.3915, EpochTime=363.05s,AvgTimePerBag=0.0529s\n",
      "Saved best model (ValPR-AUC improved to 0.3915) at epoch 3\n",
      "Epoch 4/300: TrainLoss=0.2075, ValROC-AUC=0.8837, ValPR-AUC=0.3659, EpochTime=366.40s,AvgTimePerBag=0.0534s\n",
      "No improvement in PR-AUC for 1 epoch(s).\n",
      "Epoch 5/300: TrainLoss=0.2045, ValROC-AUC=0.8840, ValPR-AUC=0.3897, EpochTime=381.94s,AvgTimePerBag=0.0557s\n",
      "No improvement in PR-AUC for 2 epoch(s).\n",
      "Epoch 6/300: TrainLoss=0.2025, ValROC-AUC=0.8871, ValPR-AUC=0.3948, EpochTime=395.94s,AvgTimePerBag=0.0577s\n",
      "Saved best model (ValPR-AUC improved to 0.3948) at epoch 6\n",
      "Epoch 7/300: TrainLoss=0.1986, ValROC-AUC=0.8904, ValPR-AUC=0.3850, EpochTime=350.94s,AvgTimePerBag=0.0512s\n",
      "No improvement in PR-AUC for 1 epoch(s).\n",
      "Epoch 8/300: TrainLoss=0.1984, ValROC-AUC=0.8921, ValPR-AUC=0.3892, EpochTime=366.19s,AvgTimePerBag=0.0534s\n",
      "No improvement in PR-AUC for 2 epoch(s).\n",
      "Epoch 9/300: TrainLoss=0.1941, ValROC-AUC=0.8936, ValPR-AUC=0.3916, EpochTime=360.03s,AvgTimePerBag=0.0525s\n",
      "No improvement in PR-AUC for 3 epoch(s).\n",
      "Epoch 10/300: TrainLoss=0.1929, ValROC-AUC=0.8928, ValPR-AUC=0.3977, EpochTime=359.31s,AvgTimePerBag=0.0524s\n",
      "Saved best model (ValPR-AUC improved to 0.3977) at epoch 10\n",
      "Epoch 11/300: TrainLoss=0.1909, ValROC-AUC=0.8997, ValPR-AUC=0.4021, EpochTime=365.33s,AvgTimePerBag=0.0533s\n",
      "Saved best model (ValPR-AUC improved to 0.4021) at epoch 11\n",
      "Epoch 12/300: TrainLoss=0.1896, ValROC-AUC=0.8887, ValPR-AUC=0.3847, EpochTime=349.61s,AvgTimePerBag=0.0510s\n",
      "No improvement in PR-AUC for 1 epoch(s).\n",
      "Epoch 13/300: TrainLoss=0.1885, ValROC-AUC=0.8934, ValPR-AUC=0.4158, EpochTime=367.59s,AvgTimePerBag=0.0536s\n",
      "Saved best model (ValPR-AUC improved to 0.4158) at epoch 13\n",
      "Epoch 14/300: TrainLoss=0.1861, ValROC-AUC=0.8905, ValPR-AUC=0.4036, EpochTime=390.23s,AvgTimePerBag=0.0569s\n",
      "No improvement in PR-AUC for 1 epoch(s).\n",
      "Epoch 15/300: TrainLoss=0.1846, ValROC-AUC=0.8898, ValPR-AUC=0.4045, EpochTime=334.90s,AvgTimePerBag=0.0488s\n",
      "No improvement in PR-AUC for 2 epoch(s).\n",
      "Epoch 16/300: TrainLoss=0.1833, ValROC-AUC=0.9004, ValPR-AUC=0.4065, EpochTime=168.44s,AvgTimePerBag=0.0246s\n",
      "No improvement in PR-AUC for 3 epoch(s).\n",
      "Epoch 17/300: TrainLoss=0.1825, ValROC-AUC=0.9042, ValPR-AUC=0.4152, EpochTime=165.02s,AvgTimePerBag=0.0241s\n",
      "No improvement in PR-AUC for 4 epoch(s).\n",
      "Epoch 18/300: TrainLoss=0.1814, ValROC-AUC=0.8851, ValPR-AUC=0.3985, EpochTime=163.79s,AvgTimePerBag=0.0239s\n",
      "No improvement in PR-AUC for 5 epoch(s).\n",
      "Epoch 19/300: TrainLoss=0.1798, ValROC-AUC=0.8971, ValPR-AUC=0.4184, EpochTime=293.76s,AvgTimePerBag=0.0428s\n",
      "Saved best model (ValPR-AUC improved to 0.4184) at epoch 19\n",
      "Epoch 20/300: TrainLoss=0.1786, ValROC-AUC=0.8879, ValPR-AUC=0.4093, EpochTime=370.76s,AvgTimePerBag=0.0540s\n",
      "No improvement in PR-AUC for 1 epoch(s).\n",
      "Epoch 21/300: TrainLoss=0.1785, ValROC-AUC=0.9033, ValPR-AUC=0.4253, EpochTime=405.38s,AvgTimePerBag=0.0591s\n",
      "Saved best model (ValPR-AUC improved to 0.4253) at epoch 21\n",
      "Epoch 22/300: TrainLoss=0.1776, ValROC-AUC=0.8946, ValPR-AUC=0.4208, EpochTime=400.86s,AvgTimePerBag=0.0584s\n",
      "No improvement in PR-AUC for 1 epoch(s).\n",
      "Epoch 23/300: TrainLoss=0.1761, ValROC-AUC=0.8948, ValPR-AUC=0.4322, EpochTime=396.48s,AvgTimePerBag=0.0578s\n",
      "Saved best model (ValPR-AUC improved to 0.4322) at epoch 23\n",
      "Epoch 24/300: TrainLoss=0.1747, ValROC-AUC=0.8988, ValPR-AUC=0.4178, EpochTime=390.51s,AvgTimePerBag=0.0569s\n",
      "No improvement in PR-AUC for 1 epoch(s).\n",
      "Epoch 25/300: TrainLoss=0.1719, ValROC-AUC=0.9005, ValPR-AUC=0.4144, EpochTime=401.71s,AvgTimePerBag=0.0586s\n",
      "No improvement in PR-AUC for 2 epoch(s).\n",
      "Epoch 26/300: TrainLoss=0.1720, ValROC-AUC=0.8970, ValPR-AUC=0.4211, EpochTime=359.46s,AvgTimePerBag=0.0524s\n",
      "No improvement in PR-AUC for 3 epoch(s).\n",
      "Epoch 27/300: TrainLoss=0.1700, ValROC-AUC=0.9036, ValPR-AUC=0.4206, EpochTime=334.18s,AvgTimePerBag=0.0487s\n",
      "No improvement in PR-AUC for 4 epoch(s).\n",
      "Epoch 28/300: TrainLoss=0.1707, ValROC-AUC=0.8991, ValPR-AUC=0.4217, EpochTime=344.21s,AvgTimePerBag=0.0502s\n",
      "No improvement in PR-AUC for 5 epoch(s).\n",
      "Epoch 29/300: TrainLoss=0.1685, ValROC-AUC=0.8892, ValPR-AUC=0.4070, EpochTime=343.54s,AvgTimePerBag=0.0501s\n",
      "No improvement in PR-AUC for 6 epoch(s).\n",
      "Epoch 30/300: TrainLoss=0.1680, ValROC-AUC=0.8962, ValPR-AUC=0.4088, EpochTime=341.36s,AvgTimePerBag=0.0498s\n",
      "No improvement in PR-AUC for 7 epoch(s).\n",
      "Epoch 31/300: TrainLoss=0.1673, ValROC-AUC=0.8986, ValPR-AUC=0.4055, EpochTime=341.88s,AvgTimePerBag=0.0498s\n",
      "No improvement in PR-AUC for 8 epoch(s).\n",
      "Epoch 32/300: TrainLoss=0.1662, ValROC-AUC=0.9013, ValPR-AUC=0.4405, EpochTime=341.72s,AvgTimePerBag=0.0498s\n",
      "Saved best model (ValPR-AUC improved to 0.4405) at epoch 32\n",
      "Epoch 33/300: TrainLoss=0.1648, ValROC-AUC=0.9032, ValPR-AUC=0.4130, EpochTime=341.88s,AvgTimePerBag=0.0498s\n",
      "No improvement in PR-AUC for 1 epoch(s).\n",
      "Epoch 34/300: TrainLoss=0.1635, ValROC-AUC=0.9079, ValPR-AUC=0.4288, EpochTime=341.92s,AvgTimePerBag=0.0498s\n",
      "No improvement in PR-AUC for 2 epoch(s).\n",
      "Epoch 35/300: TrainLoss=0.1619, ValROC-AUC=0.9047, ValPR-AUC=0.4231, EpochTime=366.33s,AvgTimePerBag=0.0534s\n",
      "No improvement in PR-AUC for 3 epoch(s).\n",
      "Epoch 36/300: TrainLoss=0.1612, ValROC-AUC=0.8999, ValPR-AUC=0.4190, EpochTime=364.26s,AvgTimePerBag=0.0531s\n",
      "No improvement in PR-AUC for 4 epoch(s).\n",
      "Epoch 37/300: TrainLoss=0.1599, ValROC-AUC=0.9030, ValPR-AUC=0.4172, EpochTime=367.87s,AvgTimePerBag=0.0536s\n",
      "No improvement in PR-AUC for 5 epoch(s).\n",
      "Epoch 38/300: TrainLoss=0.1585, ValROC-AUC=0.9108, ValPR-AUC=0.4508, EpochTime=364.67s,AvgTimePerBag=0.0532s\n",
      "Saved best model (ValPR-AUC improved to 0.4508) at epoch 38\n",
      "Epoch 39/300: TrainLoss=0.1579, ValROC-AUC=0.9076, ValPR-AUC=0.4371, EpochTime=368.44s,AvgTimePerBag=0.0537s\n",
      "No improvement in PR-AUC for 1 epoch(s).\n",
      "Epoch 40/300: TrainLoss=0.1571, ValROC-AUC=0.9078, ValPR-AUC=0.4351, EpochTime=363.88s,AvgTimePerBag=0.0530s\n",
      "No improvement in PR-AUC for 2 epoch(s).\n",
      "Epoch 41/300: TrainLoss=0.1560, ValROC-AUC=0.9003, ValPR-AUC=0.4285, EpochTime=364.30s,AvgTimePerBag=0.0531s\n",
      "No improvement in PR-AUC for 3 epoch(s).\n",
      "Epoch 42/300: TrainLoss=0.1562, ValROC-AUC=0.9099, ValPR-AUC=0.4375, EpochTime=363.63s,AvgTimePerBag=0.0530s\n",
      "No improvement in PR-AUC for 4 epoch(s).\n",
      "Epoch 43/300: TrainLoss=0.1553, ValROC-AUC=0.9069, ValPR-AUC=0.4085, EpochTime=352.04s,AvgTimePerBag=0.0513s\n",
      "No improvement in PR-AUC for 5 epoch(s).\n",
      "Epoch 44/300: TrainLoss=0.1544, ValROC-AUC=0.9091, ValPR-AUC=0.4311, EpochTime=356.87s,AvgTimePerBag=0.0520s\n",
      "No improvement in PR-AUC for 6 epoch(s).\n",
      "Epoch 45/300: TrainLoss=0.1536, ValROC-AUC=0.9022, ValPR-AUC=0.4308, EpochTime=351.10s,AvgTimePerBag=0.0512s\n",
      "No improvement in PR-AUC for 7 epoch(s).\n",
      "Epoch 46/300: TrainLoss=0.1525, ValROC-AUC=0.9038, ValPR-AUC=0.4263, EpochTime=341.17s,AvgTimePerBag=0.0497s\n",
      "No improvement in PR-AUC for 8 epoch(s).\n",
      "Epoch 47/300: TrainLoss=0.1516, ValROC-AUC=0.9108, ValPR-AUC=0.4143, EpochTime=349.22s,AvgTimePerBag=0.0509s\n",
      "No improvement in PR-AUC for 9 epoch(s).\n",
      "Epoch 48/300: TrainLoss=0.1520, ValROC-AUC=0.9140, ValPR-AUC=0.4578, EpochTime=363.06s,AvgTimePerBag=0.0529s\n",
      "Saved best model (ValPR-AUC improved to 0.4578) at epoch 48\n",
      "Epoch 49/300: TrainLoss=0.1505, ValROC-AUC=0.9089, ValPR-AUC=0.4259, EpochTime=367.35s,AvgTimePerBag=0.0535s\n",
      "No improvement in PR-AUC for 1 epoch(s).\n",
      "Epoch 50/300: TrainLoss=0.1509, ValROC-AUC=0.9124, ValPR-AUC=0.4359, EpochTime=362.52s,AvgTimePerBag=0.0528s\n",
      "No improvement in PR-AUC for 2 epoch(s).\n",
      "Epoch 51/300: TrainLoss=0.1501, ValROC-AUC=0.9126, ValPR-AUC=0.4177, EpochTime=342.44s,AvgTimePerBag=0.0499s\n",
      "No improvement in PR-AUC for 3 epoch(s).\n",
      "Epoch 52/300: TrainLoss=0.1500, ValROC-AUC=0.9030, ValPR-AUC=0.4094, EpochTime=323.40s,AvgTimePerBag=0.0471s\n",
      "No improvement in PR-AUC for 4 epoch(s).\n",
      "Epoch 53/300: TrainLoss=0.1485, ValROC-AUC=0.9130, ValPR-AUC=0.4397, EpochTime=342.06s,AvgTimePerBag=0.0499s\n",
      "No improvement in PR-AUC for 5 epoch(s).\n",
      "Epoch 54/300: TrainLoss=0.1468, ValROC-AUC=0.9155, ValPR-AUC=0.4337, EpochTime=342.89s,AvgTimePerBag=0.0500s\n",
      "No improvement in PR-AUC for 6 epoch(s).\n",
      "Epoch 55/300: TrainLoss=0.1471, ValROC-AUC=0.9120, ValPR-AUC=0.4318, EpochTime=341.77s,AvgTimePerBag=0.0498s\n",
      "No improvement in PR-AUC for 7 epoch(s).\n",
      "Epoch 56/300: TrainLoss=0.1477, ValROC-AUC=0.9147, ValPR-AUC=0.4482, EpochTime=342.84s,AvgTimePerBag=0.0500s\n",
      "No improvement in PR-AUC for 8 epoch(s).\n",
      "Epoch 57/300: TrainLoss=0.1476, ValROC-AUC=0.9223, ValPR-AUC=0.4399, EpochTime=341.62s,AvgTimePerBag=0.0498s\n",
      "No improvement in PR-AUC for 9 epoch(s).\n",
      "Epoch 58/300: TrainLoss=0.1476, ValROC-AUC=0.9148, ValPR-AUC=0.4470, EpochTime=196.00s,AvgTimePerBag=0.0286s\n",
      "No improvement in PR-AUC for 10 epoch(s).\n",
      "Epoch 59/300: TrainLoss=0.1458, ValROC-AUC=0.9106, ValPR-AUC=0.4371, EpochTime=179.41s,AvgTimePerBag=0.0262s\n",
      "No improvement in PR-AUC for 11 epoch(s).\n",
      "Epoch 60/300: TrainLoss=0.1455, ValROC-AUC=0.9010, ValPR-AUC=0.3980, EpochTime=176.89s,AvgTimePerBag=0.0258s\n",
      "No improvement in PR-AUC for 12 epoch(s).\n",
      "Epoch 61/300: TrainLoss=0.1451, ValROC-AUC=0.9159, ValPR-AUC=0.4355, EpochTime=179.94s,AvgTimePerBag=0.0262s\n",
      "No improvement in PR-AUC for 13 epoch(s).\n",
      "Epoch 62/300: TrainLoss=0.1444, ValROC-AUC=0.9137, ValPR-AUC=0.4098, EpochTime=184.69s,AvgTimePerBag=0.0269s\n",
      "No improvement in PR-AUC for 14 epoch(s).\n",
      "Epoch 63/300: TrainLoss=0.1439, ValROC-AUC=0.9062, ValPR-AUC=0.4245, EpochTime=343.04s,AvgTimePerBag=0.0500s\n",
      "No improvement in PR-AUC for 15 epoch(s).\n",
      "Epoch 64/300: TrainLoss=0.1442, ValROC-AUC=0.9104, ValPR-AUC=0.4251, EpochTime=300.85s,AvgTimePerBag=0.0439s\n",
      "No improvement in PR-AUC for 16 epoch(s).\n",
      "Epoch 65/300: TrainLoss=0.1430, ValROC-AUC=0.9150, ValPR-AUC=0.4242, EpochTime=277.04s,AvgTimePerBag=0.0404s\n",
      "No improvement in PR-AUC for 17 epoch(s).\n",
      "Epoch 66/300: TrainLoss=0.1418, ValROC-AUC=0.9087, ValPR-AUC=0.4100, EpochTime=405.90s,AvgTimePerBag=0.0592s\n",
      "No improvement in PR-AUC for 18 epoch(s).\n",
      "Epoch 67/300: TrainLoss=0.1422, ValROC-AUC=0.9078, ValPR-AUC=0.4327, EpochTime=406.21s,AvgTimePerBag=0.0592s\n",
      "No improvement in PR-AUC for 19 epoch(s).\n",
      "Epoch 68/300: TrainLoss=0.1422, ValROC-AUC=0.9109, ValPR-AUC=0.4371, EpochTime=405.08s,AvgTimePerBag=0.0590s\n",
      "No improvement in PR-AUC for 20 epoch(s).\n",
      "Early stopping at epoch 68 (no PR-AUC improvement for 20 epochs).\n",
      "Ending: 8. Training Loop\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 8. Training Loop\n",
    "# =========================\n",
    "print(\"Starting: 8. Training Loop\")\n",
    "\n",
    "# ---- Hyperparameters ----\n",
    "n_epochs = 300\n",
    "early_stop_patience = 20  # stop if no PR-AUC improvement for defined epochs\n",
    "best_val_pr = 0.0\n",
    "patience_counter = 0\n",
    "\n",
    "# ---- Sampling & Weighting Config ----\n",
    "oversample_ratio = 0.5    # oversample positives to 50% of negatives\n",
    "effective_ratio  = 1.0    # treat pos:neg equally in loss weighting\n",
    "\n",
    "# Count raw labels\n",
    "pos_count = sum(label.item() for _, _, label, _, _ in train_ds)\n",
    "neg_count = len(train_ds) - pos_count\n",
    "\n",
    "# Effective counts\n",
    "effective_pos_count = int(neg_count * oversample_ratio)\n",
    "effective_neg_count = neg_count\n",
    "\n",
    "print(f\"Original positives: {pos_count}, negatives: {neg_count}\")\n",
    "print(f\"Effective positives (oversampling {oversample_ratio*100:.0f}%): {effective_pos_count}\")\n",
    "\n",
    "# Loss weighting\n",
    "pos_weight_value = (effective_neg_count / max(effective_pos_count, 1)) * effective_ratio\n",
    "criterion = FocalLoss(alpha=pos_weight_value, gamma=2.0)\n",
    "\n",
    "# Sampler\n",
    "sampler = ImbalancedBagSampler(train_ds, pos_neg_ratio=oversample_ratio)\n",
    "\n",
    "\n",
    "# ---- Tracking Metrics ----\n",
    "metrics_dict = {\n",
    "    'epoch': [],\n",
    "    'train_loss': [],\n",
    "    'val_roc_auc': [],\n",
    "    'val_pr_auc': [],\n",
    "    'epoch_time_sec': [],\n",
    "    'avg_time_per_bag': []\n",
    "}\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    epoch_start = time.time()\n",
    "\n",
    "    # Rebuild dataloader and batch order each epoch with a fresh sampler\n",
    "    # Please reduce just use bucket_size that is a multiple of the batch_size\n",
    "    batch_sampler = BucketBatchSampler(train_ds, sampler, batch_size=20, bucket_size=200)\n",
    "    train_loader = DataLoader(train_ds, batch_sampler=batch_sampler, collate_fn=collate_fn)\n",
    "\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    n_bags = 0\n",
    "    for bag_read_level, bag_site_level, label, _, _ in train_loader:\n",
    "        n_bags += 1\n",
    "        bag_read_level = bag_read_level.to(device)\n",
    "        bag_site_level = bag_site_level.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outs, attns = model(bag_read_level, bag_site_level)\n",
    "        \n",
    "        loss = criterion(outs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if n_bags % 50000 == 0:\n",
    "            elapsed = time.time() - epoch_start\n",
    "            # print(f\"  Processed {n_bags} bags, avg time per bag: {elapsed / n_bags:.4f}s\")\n",
    "\n",
    "    total_loss /= len(train_loader)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for bag_read_level, bag_site_level, label, _, _ in val_loader:\n",
    "            bag_read_level = bag_read_level.to(device)\n",
    "            bag_site_level = bag_site_level.to(device)\n",
    "            label = label.to(device).view(-1)\n",
    "\n",
    "            # Forward pass\n",
    "            out, _ = predict_probs(model, bag_read_level, bag_site_level)\n",
    "\n",
    "            # Convert predictions and labels to list for metrics calculation\n",
    "            val_preds.extend(out.detach().cpu().numpy())\n",
    "            val_labels.extend(label.detach().cpu().numpy())\n",
    "            \n",
    "    # ---- Compute Metrics ----        \n",
    "    val_auc = roc_auc_score(val_labels, val_preds)\n",
    "    val_pr  = average_precision_score(val_labels, val_preds)\n",
    "\n",
    "    # End timer\n",
    "    epoch_time = time.time() - epoch_start\n",
    "    avg_time_per_bag = epoch_time / n_bags\n",
    "\n",
    "    # Log\n",
    "    metrics_dict['epoch'].append(epoch+1)\n",
    "    metrics_dict['train_loss'].append(total_loss)\n",
    "    metrics_dict['val_roc_auc'].append(val_auc)\n",
    "    metrics_dict['val_pr_auc'].append(val_pr)\n",
    "    metrics_dict['epoch_time_sec'].append(epoch_time)\n",
    "    metrics_dict['avg_time_per_bag'].append(avg_time_per_bag)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{n_epochs}: \"\n",
    "          f\"TrainLoss={total_loss:.4f}, \"\n",
    "          f\"ValROC-AUC={val_auc:.4f}, \"\n",
    "          f\"ValPR-AUC={val_pr:.4f}, \"\n",
    "          f\"EpochTime={epoch_time:.2f}s,\"\n",
    "          f\"AvgTimePerBag={avg_time_per_bag:.4f}s\")\n",
    "\n",
    "    # ---- Early Stopping & Model Saving ----\n",
    "    if val_pr > best_val_pr:\n",
    "        best_val_pr = val_pr\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), f\"Models/epoch{epoch+1}_valpr{val_pr:.2f}.pth\")\n",
    "        model_name = f\"epoch{epoch+1}_valpr{val_pr:.2f}.pth\"\n",
    "        print(f\"Saved best model (ValPR-AUC improved to {val_pr:.4f}) at epoch {epoch+1}\")\n",
    "        \n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"No improvement in PR-AUC for {patience_counter} epoch(s).\")\n",
    "\n",
    "        if patience_counter >= early_stop_patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1} (no PR-AUC improvement for {early_stop_patience} epochs).\")\n",
    "            break\n",
    "\n",
    "print(\"Ending: 8. Training Loop\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285e122c",
   "metadata": {},
   "source": [
    "### Get the training set metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f78361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming metrics_dict already exists\n",
    "# Convert the dictionary to a DataFrame\n",
    "df = pd.DataFrame(metrics_dict)\n",
    "\n",
    "# Define the file path for CSV\n",
    "file_path = 'metrics.csv'\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(file_path, index=False)\n",
    "\n",
    "print(f\"Dictionary saved to {file_path} as CSV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "276b3145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_eval_models(model_path, \n",
    "                         mode=\"both\", \n",
    "                         top_k=5, \n",
    "                         device=\"cpu\", \n",
    "                         test_loader=None):\n",
    "    \"\"\"\n",
    "    Load models (single best, top-k ensemble) and evaluate on test set.\n",
    "    Saves predictions separately for each mode.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Parse saved models ---\n",
    "    pattern = r\"epoch\\d+_valpr(\\d+\\.\\d+)\\.pth\"\n",
    "    models = []\n",
    "    for f in os.listdir(model_path):\n",
    "        match = re.match(pattern, f)\n",
    "        if match:\n",
    "            pr_auc = float(match.group(1))\n",
    "            models.append((f, pr_auc))\n",
    "    if not models:\n",
    "        raise ValueError(\"No valid model files found in directory.\")\n",
    "\n",
    "    # --- Sort descending by PR-AUC ---\n",
    "    models.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    # --- Load single best ---\n",
    "    if mode in [\"single\", \"both\"]:\n",
    "        best_model_file, best_pr = models[0]\n",
    "        model = AttentionMIL_v2(\n",
    "            read_dim=test_loader.dataset.read_dim,\n",
    "            site_dim=test_loader.dataset.site_dim,\n",
    "            hidden_dim=128,\n",
    "            dropout=0.2,\n",
    "            n_heads=4\n",
    "        ).to(device)\n",
    "        model.load_state_dict(torch.load(f\"{model_path}/{best_model_file}\", map_location=device))\n",
    "        model.eval()\n",
    "        results[\"single_model\"] = model\n",
    "        results[\"single_name\"] = best_model_file\n",
    "\n",
    "    # --- Load top-k ensemble ---\n",
    "    if mode in [\"topk\", \"both\"]:\n",
    "        top_models = models[:top_k]\n",
    "        ensemble = []\n",
    "        for m_name, pr in top_models:\n",
    "            m = AttentionMIL_v2(\n",
    "                read_dim=test_loader.dataset.read_dim,\n",
    "                site_dim=test_loader.dataset.site_dim,\n",
    "                hidden_dim=128,\n",
    "                dropout=0.2,\n",
    "                n_heads=4\n",
    "            ).to(device)\n",
    "            m.load_state_dict(torch.load(f\"{model_path}/{m_name}\", map_location=device))\n",
    "            m.eval()\n",
    "            ensemble.append(m)\n",
    "        results[\"ensemble_models\"] = ensemble\n",
    "        results[\"ensemble_names\"] = [m[0] for m in top_models]\n",
    "\n",
    "    # --- Evaluation ---\n",
    "    if test_loader is not None:\n",
    "        y_true, y_pred_single, y_pred_ens = [], [], []\n",
    "        single_rows, ens_rows = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for bag_read_level, bag_site_level, label, tid, pos in test_loader:\n",
    "                bag_read_level = bag_read_level.to(device)\n",
    "                bag_site_level = bag_site_level.to(device)\n",
    "                label = label.to(device).view(-1)\n",
    "\n",
    "                # Single best model\n",
    "                if \"single_model\" in results:\n",
    "                    out, _ = results[\"single_model\"](bag_read_level, bag_site_level)\n",
    "                    prob = torch.sigmoid(out).item()\n",
    "                    y_pred_single.append(prob)\n",
    "                    single_rows.append({\n",
    "                        'transcript_id': tid[0],\n",
    "                        'transcript_position': pos.item(),\n",
    "                        'score': prob\n",
    "                    })\n",
    "\n",
    "                # Ensemble\n",
    "                if \"ensemble_models\" in results:\n",
    "                    preds = []\n",
    "                    for m in results[\"ensemble_models\"]:\n",
    "                        out, _ = m(bag_read_level, bag_site_level)\n",
    "                        preds.append(torch.sigmoid(out).item())\n",
    "                    avg_prob = sum(preds) / len(preds)\n",
    "                    y_pred_ens.append(avg_prob)\n",
    "                    ens_rows.append({\n",
    "                        'transcript_id': tid[0],\n",
    "                        'transcript_position': pos.item(),\n",
    "                        'score': avg_prob\n",
    "                    })\n",
    "\n",
    "                y_true.append(label.item())\n",
    "\n",
    "        # Compute and save results\n",
    "        if y_pred_single:\n",
    "            roc = roc_auc_score(y_true, y_pred_single)\n",
    "            pr  = average_precision_score(y_true, y_pred_single)\n",
    "            print(f\"[Single Best] ROC-AUC={roc:.4f}, PR-AUC={pr:.4f}\")\n",
    "            pd.DataFrame(single_rows).to_csv(\"Results/best_single_test_data_output.csv\", index=False)\n",
    "\n",
    "        if y_pred_ens:\n",
    "            roc = roc_auc_score(y_true, y_pred_ens)\n",
    "            pr  = average_precision_score(y_true, y_pred_ens)\n",
    "            print(f\"[Top-{top_k} Ensemble] ROC-AUC={roc:.4f}, PR-AUC={pr:.4f}\")\n",
    "            pd.DataFrame(ens_rows).to_csv(f\"Results/top_{top_k}_ensemble_test_data_output.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13260a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Single Best] ROC-AUC=0.9006, PR-AUC=0.4615\n",
      "[Top-5 Ensemble] ROC-AUC=0.8972, PR-AUC=0.4618\n"
     ]
    }
   ],
   "source": [
    "model_path = \"Models/\"\n",
    "\n",
    "load_and_eval_models(model_path = model_path,mode = \"both\", top_k = 5,test_loader = test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "733ac8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Single Best] ROC-AUC=0.9092, PR-AUC=0.4593\n",
      "[Top-3 Ensemble] ROC-AUC=0.9070, PR-AUC=0.4529\n"
     ]
    }
   ],
   "source": [
    "model_path = \"Models/\"\n",
    "\n",
    "load_and_eval_models(model_path = model_path,mode = \"both\", top_k = 3,test_loader = test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49306dbc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1522291",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c59dfd7",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0313464f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# ✅ WHAT YOU MUST UPDATE IF TRAINING SCRIPT CHANGES\n",
    "\n",
    "Any time you change preprocessing or architecture in the **training script**, you must copy over the same edits into this inference script in these sections:\n",
    "\n",
    "### ✅ 1️⃣ 7-mer encoding\n",
    "\n",
    "```python\n",
    "def encode_7mer(...)\n",
    "```\n",
    "\n",
    "### ✅ 2️⃣ Numeric feature selection\n",
    "\n",
    "```python\n",
    "numeric_feats = g[[ ... ]]\n",
    "```\n",
    "\n",
    "### ✅ 3️⃣ Model architecture\n",
    "\n",
    "```python\n",
    "class AttentionMIL(...)\n",
    "```\n",
    "\n",
    "and `input_dim`, `hidden_dim` if changed.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d68c4278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 0. Imports & Setup\n",
    "# =========================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import pickle\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "import os, re\n",
    "\n",
    "\n",
    "# Reproducibility\n",
    "RNG = 42\n",
    "np.random.seed(RNG)\n",
    "torch.manual_seed(RNG)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d8e96fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Raw File/dataset0.csv\n",
      "Encoding 7mers\n",
      "Read-level dim: 31 | Site-level dim: 37\n",
      "✅ Dataset initialized: read_dim = 31, site_dim = 37\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 1. Load dataset.csv\n",
    "# =========================\n",
    "file_path = \"Raw File/\"\n",
    "file_name = \"dataset0.csv\"\n",
    "\n",
    "print(f\"Loading {file_path}{file_name}\")\n",
    "reads_df = pd.read_csv(f\"{file_path}{file_name}\")\n",
    "\n",
    "columns_to_drop = ['Unnamed: 0']\n",
    "reads_df = reads_df.drop(columns_to_drop, axis=1, errors='ignore')\n",
    "\n",
    "# sorry cherron i cannot with the colnames\n",
    "reads_df = reads_df.rename(columns={\n",
    "    'ID': 'transcript_id',\n",
    "    'POS': 'transcript_position',\n",
    "    'SEQ': '7mer'\n",
    "})\n",
    "reads_df['n_reads'] = reads_df.groupby(['transcript_id', 'transcript_position']).transform('size')\n",
    "# =========================\n",
    "# 2. 7-mer Encoding (MUST MATCH TRAINING)\n",
    "# =========================\n",
    "print(\"Encoding 7mers\")\n",
    "def encode_drach_compact(seq):\n",
    "    \"\"\"\n",
    "    Compact one-hot encoding of a 7-mer centered on a DRACH motif.\n",
    "    Positions:\n",
    "    - 0: full one-hot (A,C,G,T) → 4 dims\n",
    "    - 1: D (A,G,T) → 3 dims\n",
    "    - 2: R (A,G)   → 2 dims\n",
    "    - 3: A (fixed) → 0 dims\n",
    "    - 4: C (fixed) → 0 dims\n",
    "    - 5: H (A,C,T) → 3 dims\n",
    "    - 6: full one-hot (A,C,G,T) → 4 dims\n",
    "    Total: 16-dimensional vector\n",
    "    \"\"\"\n",
    "    encoding = []\n",
    "\n",
    "    base = seq[0]\n",
    "    encoding.extend(one_hot_base(base, ['A', 'C', 'G', 'T']))\n",
    "\n",
    "    base = seq[1]\n",
    "    encoding.extend(one_hot_base(base, ['A', 'G', 'T']))  # D\n",
    "\n",
    "    base = seq[2]\n",
    "    encoding.extend(one_hot_base(base, ['A', 'G']))       # R\n",
    "\n",
    "    # skip position 3 (always A)\n",
    "    # skip position 4 (always C)\n",
    "\n",
    "    base = seq[5]\n",
    "    encoding.extend(one_hot_base(base, ['A', 'C', 'T']))  # H\n",
    "\n",
    "    base = seq[6]\n",
    "    encoding.extend(one_hot_base(base, ['A', 'C', 'G', 'T']))\n",
    "\n",
    "    return np.array(encoding, dtype=np.float32)\n",
    "\n",
    "def one_hot_base(base, allowed):\n",
    "    \"\"\"One-hot encode base using only allowed bases.\"\"\"\n",
    "    vec = [0] * len(allowed)\n",
    "    if base in allowed:\n",
    "        vec[allowed.index(base)] = 1\n",
    "    return vec\n",
    "\n",
    "reads_df['7mer_emb'] = reads_df['7mer'].apply(encode_drach_compact)\n",
    "\n",
    "# =========================\n",
    "# 3. Dataset Class (NO LABELS NEEDED)\n",
    "# =========================\n",
    "class MILReadDatasetInference(Dataset):\n",
    "    def __init__(self, reads_df, n_reads_per_site=None, agg_config=None):\n",
    "        \"\"\"\n",
    "        reads_df: DataFrame with read-level rows:\n",
    "                  ['transcript_id','transcript_position','7mer_emb,\n",
    "                   'PreTime','PreSD','PreMean','InTime','InSD','InMean','PostTime','PostSD','PostMean',...]\n",
    "        n_reads_per_site: int or None\n",
    "            - int: sample at most this many reads per site\n",
    "            - None: use all reads\n",
    "        agg_config: dict for aggregation at site level, e.g.\n",
    "            {\n",
    "              \"Time\": [\"min\",\"max\",\"mean\",\"25\",\"75\"],\n",
    "              \"SD\": [\"mean\"],\n",
    "              \"Mean\": [\"mean\"]\n",
    "            }\n",
    "        \"\"\"\n",
    "\n",
    "        self.n_reads_per_site = n_reads_per_site\n",
    "        self.groups = reads_df.groupby(['transcript_id', 'transcript_position'])\n",
    "        self.bags = list(self.groups.groups.keys())\n",
    "        self.reads_df = reads_df\n",
    "        # self.use_delta = True  # <--- toggle delta features on read levels\n",
    "\n",
    "        # -----------------------------\n",
    "        # Feature toggle switches\n",
    "        # -----------------------------\n",
    "        # Comment/uncomment entries to include/exclude features\n",
    "        self.read_feature_flags = {\n",
    "            \"numeric\": True,   # PreTime..PostMean\n",
    "            \"7mer\": True,      # 7mer embedding at read-level\n",
    "            \"delta\": True,\n",
    "        }\n",
    "        self.site_feature_flags = {\n",
    "            \"numeric_aggs\": True,  # aggregated Time/SD/Mean stats\n",
    "            \"7mer\": True,          # site-level 7mer embedding\n",
    "        }\n",
    "\n",
    "        # Default aggregation if not passed\n",
    "        self.agg_config = agg_config or {\n",
    "            \"Time\": [\"min\", \"max\", \"mean\", \"25\", \"75\"],\n",
    "            \"SD\": [\"mean\"],\n",
    "            \"Mean\": [\"mean\"]\n",
    "        }\n",
    "\n",
    "        # Bag lengths\n",
    "        self.bag_lengths = {k: len(v) for k, v in self.groups}\n",
    "\n",
    "        # -----------------------------\n",
    "        # Infer dimensions\n",
    "        # -----------------------------\n",
    "        dummy_bag = self[0]\n",
    "        _, _, _, _ = dummy_bag\n",
    "        print(f\"✅ Dataset initialized: read_dim = {self.read_dim}, site_dim = {self.site_dim}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.bags)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tid, pos = self.bags[idx]\n",
    "        g = self.groups.get_group((tid, pos))\n",
    "\n",
    "        # -----------------------------\n",
    "        # Read-level matrix\n",
    "        # -----------------------------\n",
    "        read_parts = []\n",
    "\n",
    "        if self.read_feature_flags[\"numeric\"]:\n",
    "            numeric_feats = g[[\n",
    "                'PreTime','PreSD','PreMean',\n",
    "                'InTime','InSD','InMean',\n",
    "                'PostTime','PostSD','PostMean'\n",
    "            ]].values.astype(np.float32)\n",
    "            read_parts.append(numeric_feats)\n",
    "\n",
    "        if self.read_feature_flags[\"7mer\"]:\n",
    "            kmer_list = list(g['7mer_emb'].values)\n",
    "            kmer_emb_read = np.vstack(kmer_list).astype(np.float32)\n",
    "            read_parts.append(kmer_emb_read)\n",
    "\n",
    "\n",
    "        if self.read_feature_flags[\"delta\"]:\n",
    "            deltas = []\n",
    "            # Time deltas\n",
    "            deltas.append(numeric_feats[:, 3] - numeric_feats[:, 0])  # InTime - PreTime\n",
    "            deltas.append(numeric_feats[:, 6] - numeric_feats[:, 3])  # PostTime - InTime\n",
    "            # SD deltas\n",
    "            deltas.append(numeric_feats[:, 4] - numeric_feats[:, 1])  # InSD - PreSD\n",
    "            deltas.append(numeric_feats[:, 7] - numeric_feats[:, 4])  # PostSD - InSD\n",
    "            # Mean deltas\n",
    "            deltas.append(numeric_feats[:, 5] - numeric_feats[:, 2])  # InMean - PreMean\n",
    "            deltas.append(numeric_feats[:, 8] - numeric_feats[:, 5])  # PostMean - InMean\n",
    "\n",
    "            delta_feats = np.stack(deltas, axis=1)  # shape (n_reads, 6)\n",
    "            read_parts.append(delta_feats)\n",
    "        \n",
    "        bag_read_level = np.concatenate(read_parts, axis=1)\n",
    "\n",
    "        # Random subsampling\n",
    "        if self.n_reads_per_site is not None and bag_read_level.shape[0] > self.n_reads_per_site:\n",
    "            idxs = np.random.choice(bag_read_level.shape[0], self.n_reads_per_site, replace=False)\n",
    "            bag_read_level = bag_read_level[idxs]\n",
    "\n",
    "        # -----------------------------\n",
    "        # Site-level vector\n",
    "        # -----------------------------\n",
    "        site_parts = []\n",
    "\n",
    "        if self.site_feature_flags[\"numeric_aggs\"]:\n",
    "            site_aggs = []\n",
    "            groups = {\"Time\": [0, 3, 6], \"SD\": [1, 4, 7], \"Mean\": [2, 5, 8]}\n",
    "            for feat_type, idx_list in groups.items():\n",
    "                stats = self.agg_config.get(feat_type, [])\n",
    "                for col_idx in idx_list:\n",
    "                    vals = numeric_feats[:, col_idx].astype(np.float32)\n",
    "                    for stat in stats:\n",
    "                        if stat == \"min\": site_aggs.append(np.min(vals))\n",
    "                        elif stat == \"max\": site_aggs.append(np.max(vals))\n",
    "                        elif stat == \"mean\": site_aggs.append(np.mean(vals))\n",
    "                        elif stat == \"25\": site_aggs.append(np.percentile(vals, 25))\n",
    "                        elif stat == \"75\": site_aggs.append(np.percentile(vals, 75))\n",
    "            site_parts.append(np.array(site_aggs, dtype=np.float32))\n",
    "\n",
    "        if self.site_feature_flags[\"7mer\"]:\n",
    "            first_kmer = np.asarray(g['7mer_emb'].iloc[0], dtype=np.float32).ravel()\n",
    "            site_parts.append(first_kmer)\n",
    "            \n",
    "\n",
    "        bag_site_level = np.concatenate(site_parts, axis=0).astype(np.float32)\n",
    "\n",
    "        # Store dims once (for printing at init)\n",
    "        if not hasattr(self, \"read_dim\"):\n",
    "            self.read_dim = bag_read_level.shape[1]\n",
    "            self.site_dim = bag_site_level.shape[0]\n",
    "            print(f\"Read-level dim: {self.read_dim} | Site-level dim: {self.site_dim}\")\n",
    "\n",
    "        return (torch.tensor(bag_read_level, dtype=torch.float32),\n",
    "                torch.tensor(bag_site_level, dtype=torch.float32),\n",
    "                tid, pos)\n",
    "\n",
    "\n",
    "# Create dataset & dataloader\n",
    "inference_ds = MILReadDatasetInference(reads_df)\n",
    "inference_loader = torch.utils.data.DataLoader(inference_ds, batch_size=1, shuffle=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a769e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded trained model weights\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 4. Define Model (MUST MATCH TRAINING)\n",
    "# =========================\n",
    "class MultiHeadAttentionPool(nn.Module):\n",
    "    def __init__(self, hidden_dim, n_heads=4):\n",
    "        super().__init__()\n",
    "        self.n_heads = n_heads\n",
    "        # project to head space then scalar score per head\n",
    "        self.proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.head_score = nn.Linear(hidden_dim, n_heads)  # outputs (batch, n_instances, n_heads)\n",
    "    \n",
    "    def forward(self, H):  # H: (B, N, hidden_dim)\n",
    "        # Optionally nonlinearity\n",
    "        S = torch.tanh(self.proj(H))            # (B, N, hidden_dim)\n",
    "        scores = self.head_score(S)             # (B, N, n_heads)\n",
    "        attn = torch.softmax(scores, dim=1)     # softmax over instances per head\n",
    "        # attn: (B, N, n_heads). compute per-head pooled vectors:\n",
    "        # transpose H to (B, hidden_dim, N) to do matmul\n",
    "        pooled = []\n",
    "        for h in range(self.n_heads):\n",
    "            a = attn[..., h].unsqueeze(-1)      # (B, N, 1)\n",
    "            m = torch.sum(a * H, dim=1)         # (B, hidden_dim)\n",
    "            pooled.append(m)\n",
    "        # concat head outputs\n",
    "        M = torch.cat(pooled, dim=1)           # (B, hidden_dim * n_heads)\n",
    "        return M, attn                         # attn shape (B, N, n_heads)\n",
    "\n",
    "class AttentionMIL_v2(nn.Module):\n",
    "    def __init__(self, read_dim, site_dim, hidden_dim=128, n_heads=4, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.read_encoder = nn.Sequential(\n",
    "            nn.Linear(read_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self.site_encoder = nn.Sequential(\n",
    "            nn.Linear(site_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self.pool = MultiHeadAttentionPool(hidden_dim, n_heads=n_heads)\n",
    "        # project pooled concat (hidden_dim * n_heads) back to hidden_dim\n",
    "        self.pool_proj = nn.Linear(hidden_dim * n_heads, hidden_dim)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim*2, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, bag_read_level, bag_site_level):\n",
    "        # bag_read_level: (B,N,read_dim)\n",
    "        H = self.read_encoder(bag_read_level)   # (B,N,hidden_dim)\n",
    "        M_concat, attn = self.pool(H)           # (B, hidden_dim * n_heads)\n",
    "        M = self.pool_proj(M_concat)            # (B, hidden_dim)\n",
    "        site = self.site_encoder(bag_site_level) # (B, hidden_dim)\n",
    "        combined = torch.cat([M, site], dim=-1) # (B, hidden_dim*2)\n",
    "        out = self.classifier(combined).view(-1)\n",
    "        return out, attn\n",
    "\n",
    "\n",
    "read_dim = inference_ds.read_dim\n",
    "site_dim = inference_ds.site_dim\n",
    "model = AttentionMIL_v2(read_dim=read_dim, site_dim=site_dim, hidden_dim=128, dropout=0.2).to(device)\n",
    "model.eval()\n",
    "print(\"Loaded trained model weights\")\n",
    "\n",
    "# =========================\n",
    "# 5. Inference & Output\n",
    "# =========================\n",
    "def run_inference(model_path, loader, \n",
    "                  mode=\"both\", top_k=5, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Inference pipeline:\n",
    "      - Loads models (best single, top-k ensemble)\n",
    "      - Runs inference on loader (no labels needed)\n",
    "      - Saves prediction outputs to CSV\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Parse saved models ---\n",
    "    pattern = r\"epoch\\d+_valpr(\\d+\\.\\d+)\\.pth\"\n",
    "    models = []\n",
    "    for f in os.listdir(model_path):\n",
    "        match = re.match(pattern, f)\n",
    "        if match:\n",
    "            pr_auc = float(match.group(1))\n",
    "            models.append((f, pr_auc))\n",
    "    if not models:\n",
    "        raise ValueError(\"No valid model files found in directory.\")\n",
    "\n",
    "    # --- Sort descending by PR-AUC ---\n",
    "    models.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    # --- Load single best ---\n",
    "    if mode in [\"single\", \"both\"]:\n",
    "        best_model_file, _ = models[0]\n",
    "        model = AttentionMIL_v2(\n",
    "            read_dim=loader.dataset.read_dim,\n",
    "            site_dim=loader.dataset.site_dim,\n",
    "            hidden_dim=128,\n",
    "            dropout=0.2,\n",
    "            n_heads=4\n",
    "        ).to(device)\n",
    "        model.load_state_dict(torch.load(f\"{model_path}/{best_model_file}\", map_location=device))\n",
    "        model.eval()\n",
    "        results[\"single_model\"] = model\n",
    "        results[\"single_name\"] = best_model_file\n",
    "\n",
    "    # --- Load top-k ensemble ---\n",
    "    if mode in [\"topk\", \"both\"]:\n",
    "        top_models = models[:top_k]\n",
    "        ensemble = []\n",
    "        for m_name, _ in top_models:\n",
    "            m = AttentionMIL_v2(\n",
    "                read_dim=loader.dataset.read_dim,\n",
    "                site_dim=loader.dataset.site_dim,\n",
    "                hidden_dim=128,\n",
    "                dropout=0.2,\n",
    "                n_heads=4\n",
    "            ).to(device)\n",
    "            m.load_state_dict(torch.load(f\"{model_path}/{m_name}\", map_location=device))\n",
    "            m.eval()\n",
    "            ensemble.append(m)\n",
    "        results[\"ensemble_models\"] = ensemble\n",
    "        results[\"ensemble_names\"] = [m[0] for m in top_models]\n",
    "\n",
    "    # --- Inference (no labels) ---\n",
    "    single_rows, ens_rows = [], []\n",
    "    with torch.no_grad():\n",
    "        for bag_read_level, bag_site_level, tid, pos in loader:\n",
    "            bag_read_level = bag_read_level.to(device)\n",
    "            bag_site_level = bag_site_level.to(device)\n",
    "\n",
    "            # Single best model\n",
    "            if \"single_model\" in results:\n",
    "                out, _ = results[\"single_model\"](bag_read_level, bag_site_level)\n",
    "                prob = torch.sigmoid(out).item()\n",
    "                single_rows.append({\n",
    "                    'transcript_id': tid[0],\n",
    "                    'transcript_position': pos.item(),\n",
    "                    'score': prob\n",
    "                })\n",
    "\n",
    "            # Ensemble\n",
    "            if \"ensemble_models\" in results:\n",
    "                preds = []\n",
    "                for m in results[\"ensemble_models\"]:\n",
    "                    out, _ = m(bag_read_level, bag_site_level)\n",
    "                    preds.append(torch.sigmoid(out).item())\n",
    "                avg_prob = sum(preds) / len(preds)\n",
    "                ens_rows.append({\n",
    "                    'transcript_id': tid[0],\n",
    "                    'transcript_position': pos.item(),\n",
    "                    'score': avg_prob\n",
    "                })\n",
    "\n",
    "    # --- Save outputs ---\n",
    "    outputs = {}\n",
    "    if single_rows:\n",
    "        df_single = pd.DataFrame(single_rows)\n",
    "        df_single.to_csv(f\"Results/best_single_inference_of_{file_name}\", index=False)\n",
    "        print(\"Saved best_single_inference.csv\")\n",
    "        outputs[\"single\"] = df_single\n",
    "\n",
    "    if ens_rows:\n",
    "        df_ens = pd.DataFrame(ens_rows)\n",
    "        df_ens.to_csv(f\"Results/top_{top_k}_ensemble_inference_of_{file_name}\", index=False)\n",
    "        print(f\"Saved top_{top_k}_ensemble_inference.csv\")\n",
    "        outputs[\"ensemble\"] = df_ens\n",
    "\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "643e43c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best_single_inference.csv\n",
      "Saved top_5_ensemble_inference.csv\n",
      "     transcript_id  transcript_position     score\n",
      "0  ENST00000000233                  244  0.220471\n",
      "1  ENST00000000233                  261  0.279924\n",
      "2  ENST00000000233                  316  0.081724\n",
      "3  ENST00000000233                  332  0.336998\n",
      "4  ENST00000000233                  368  0.205862\n",
      "     transcript_id  transcript_position     score\n",
      "0  ENST00000000233                  244  0.269454\n",
      "1  ENST00000000233                  261  0.314499\n",
      "2  ENST00000000233                  316  0.100107\n",
      "3  ENST00000000233                  332  0.346790\n",
      "4  ENST00000000233                  368  0.290033\n"
     ]
    }
   ],
   "source": [
    "model_path = \"Models/\"\n",
    "results = run_inference(model_path, mode=\"both\", top_k=5, loader=inference_loader, device=device)\n",
    "print(results[\"single\"].head())\n",
    "print(results[\"ensemble\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "643c064b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
